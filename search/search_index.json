{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The Road to Zero This website describes how to develop your own zero day vulnerabilities in iOS. Preface This book has come about because having written a book on iOS Crash Dump Analysis, I found that most of my audience were security-focussed engineers. I share the same passion. I have been studying various \"Crack Me\" challenges. I thought I was doing the correct preparation for vulnerability analysis. When I looked at successful exploits, mostly on Google Project Zero , I found there was a technique gap. Not only do you need to apply standard techniques, you need to apply them on unfamiliar APIs, such as IOSurface and XPC . So I naturally looked at Crack Me challenges using those APIs. I wasn't able to find any. What I am attempting to do is to document my journey in acquiring the skills to find Zero Day Vulnerabilities on iOS in the form of a book. That is so that future engineers will have a book to take them along the same journey. So the nature of this book is mostly a tutorial but with appropriate theory explanations or system knowledge explained along the way. I take the view that when you are exploring new things, cost barriers are magnified because you are not sure at the time whether you will stick with it or enjoy it. Paying a lot of money for golf clubs is a straightforward choice if you've already fallen in love with the game. So I am going to work on the basis the reader has modest resources to hand (compared to the professionals in this area). I assume you have an iDevice, a Mac, an Xcode developer account, and maybe software, free or licensed at modest cost. There is one last element I intend to add to the mix. The Hacker Mentality. This is the attitude of mind where an innocent piece of information can be viewed through a hacker's lens. That offers the foothold for us to commence experimentation and discovery that then later will result in new vulnerabilities. If I am successful, I hope this book will become the handbook of vulnerability craftsmanship in the same way that Code Complete became the handbook of software craftsmanship. One thing in particular that attracts me to iOS is that its one of the hardest platforms to circumvent. It may turn out I don't reach the high bar needed to make progress on this platform. But if it was going to be easy, what would be the point in trying? Disclaimer Copyright Faisal Memon 2021. All Rights Reserved. This publication is provided \"as is\" without warranty of any kind, either express or implied, including, but not limited to, the implied warranties of merchantability, fitness for a particular purpose, or non-infringement. This publication could include technical inaccuracies or typographical errors. Changes are periodically added to the information herein. These changes will be incorporated in new editions of the publication. Apple makes no explicit or implied endorsement of this work. Materials in this book have been determined from public information sources and binaries, or materials provided by the Apple Software Development Kits. Positions held by the author, as an employee or contractor, at past or future companies and institutions makes no explicit or implied endorsement of this work by those entities. Trademarks Every effort has been made to identify trademark terms in this text. If there is an error or omission, please contact the author. We have thus far recognized the following trademarks: iOS Darwin UNIX NeXT macOS tvOS watchOS iPhone iPod iPad Acknowledgements I'd like to acknowledge the help and support of my colleagues for writing this book. Putting together this work was only possible because it was built upon generously provided open source tools which made writing the text of the book a pleasure. Lastly, I'd like to thank my supportive family whilst I was locked in my study, and largely absent. Thank you Junghyun, and Christopher.","title":"Home"},{"location":"#the-road-to-zero","text":"This website describes how to develop your own zero day vulnerabilities in iOS.","title":"The Road to Zero"},{"location":"#preface","text":"This book has come about because having written a book on iOS Crash Dump Analysis, I found that most of my audience were security-focussed engineers. I share the same passion. I have been studying various \"Crack Me\" challenges. I thought I was doing the correct preparation for vulnerability analysis. When I looked at successful exploits, mostly on Google Project Zero , I found there was a technique gap. Not only do you need to apply standard techniques, you need to apply them on unfamiliar APIs, such as IOSurface and XPC . So I naturally looked at Crack Me challenges using those APIs. I wasn't able to find any. What I am attempting to do is to document my journey in acquiring the skills to find Zero Day Vulnerabilities on iOS in the form of a book. That is so that future engineers will have a book to take them along the same journey. So the nature of this book is mostly a tutorial but with appropriate theory explanations or system knowledge explained along the way. I take the view that when you are exploring new things, cost barriers are magnified because you are not sure at the time whether you will stick with it or enjoy it. Paying a lot of money for golf clubs is a straightforward choice if you've already fallen in love with the game. So I am going to work on the basis the reader has modest resources to hand (compared to the professionals in this area). I assume you have an iDevice, a Mac, an Xcode developer account, and maybe software, free or licensed at modest cost. There is one last element I intend to add to the mix. The Hacker Mentality. This is the attitude of mind where an innocent piece of information can be viewed through a hacker's lens. That offers the foothold for us to commence experimentation and discovery that then later will result in new vulnerabilities. If I am successful, I hope this book will become the handbook of vulnerability craftsmanship in the same way that Code Complete became the handbook of software craftsmanship. One thing in particular that attracts me to iOS is that its one of the hardest platforms to circumvent. It may turn out I don't reach the high bar needed to make progress on this platform. But if it was going to be easy, what would be the point in trying?","title":"Preface"},{"location":"#disclaimer","text":"Copyright Faisal Memon 2021. All Rights Reserved. This publication is provided \"as is\" without warranty of any kind, either express or implied, including, but not limited to, the implied warranties of merchantability, fitness for a particular purpose, or non-infringement. This publication could include technical inaccuracies or typographical errors. Changes are periodically added to the information herein. These changes will be incorporated in new editions of the publication. Apple makes no explicit or implied endorsement of this work. Materials in this book have been determined from public information sources and binaries, or materials provided by the Apple Software Development Kits. Positions held by the author, as an employee or contractor, at past or future companies and institutions makes no explicit or implied endorsement of this work by those entities.","title":"Disclaimer"},{"location":"#trademarks","text":"Every effort has been made to identify trademark terms in this text. If there is an error or omission, please contact the author. We have thus far recognized the following trademarks: iOS Darwin UNIX NeXT macOS tvOS watchOS iPhone iPod iPad","title":"Trademarks"},{"location":"#acknowledgements","text":"I'd like to acknowledge the help and support of my colleagues for writing this book. Putting together this work was only possible because it was built upon generously provided open source tools which made writing the text of the book a pleasure. Lastly, I'd like to thank my supportive family whilst I was locked in my study, and largely absent. Thank you Junghyun, and Christopher.","title":"Acknowledgements"},{"location":"Author/","text":"About the Author Biography Faisal Memon has had a long career in engineering. He has worked on most layers of the software stack from probing noisy electrical circuits, to writing Operating System software, middleware, and apps. Having worn the hats of software tester, developer, tech lead, architect and CTO he sees problems from a rounded perspective. Other work Faisal has also authored the book, \"iOS Crash Dump Analysis\", Second Edition. Purchase from Amazon.com Purchase from Amazon.co.uk","title":"About"},{"location":"Author/#about-the-author","text":"","title":"About the Author"},{"location":"Author/#biography","text":"Faisal Memon has had a long career in engineering. He has worked on most layers of the software stack from probing noisy electrical circuits, to writing Operating System software, middleware, and apps. Having worn the hats of software tester, developer, tech lead, architect and CTO he sees problems from a rounded perspective.","title":"Biography"},{"location":"Author/#other-work","text":"Faisal has also authored the book, \"iOS Crash Dump Analysis\", Second Edition. Purchase from Amazon.com Purchase from Amazon.co.uk","title":"Other work"},{"location":"Bibliography/","text":"Bibliography Reference Resource Link Google Project Zero https://googleprojectzero.blogspot.com/p/about-project-zero.html Code Complete Code Complete. Second Edition. 1st Series 0735619670. Microsoft Press. Why I Love and Don't Love Offensive Work https://www.youtube.com/watch?v=8QRnOpjmneo The Road to Zero GitHub https://github.com/faisalmemon/the-road-to-zero Exploit Database Git Repository https://github.com/offensive-security/exploitdb A Programmer's Guide to the Mach System Calls A Programmer's Guide to the Mach System Calls by Linda R. Walmer and Mary R. Thompson, Carnegie-Mellon University, 1988. Mach Mach Concepts by NeXT Computer, Inc. 1995. Mirror Website","title":"Bibliography"},{"location":"Bibliography/#bibliography","text":"Reference Resource Link Google Project Zero https://googleprojectzero.blogspot.com/p/about-project-zero.html Code Complete Code Complete. Second Edition. 1st Series 0735619670. Microsoft Press. Why I Love and Don't Love Offensive Work https://www.youtube.com/watch?v=8QRnOpjmneo The Road to Zero GitHub https://github.com/faisalmemon/the-road-to-zero Exploit Database Git Repository https://github.com/offensive-security/exploitdb A Programmer's Guide to the Mach System Calls A Programmer's Guide to the Mach System Calls by Linda R. Walmer and Mary R. Thompson, Carnegie-Mellon University, 1988. Mach Mach Concepts by NeXT Computer, Inc. 1995. Mirror Website","title":"Bibliography"},{"location":"BootingDevelopmentKernel/","text":"Booting and exploring a Development Kernel This section is a practical tutorial on how to setup a system for interactive kernel level debugging. At a high level, this is our workflow: Data Safety Experimenting with kernels can be like playing with fire. The target machine must be throwaway; it might end up no longer booting, or be stuck in a boot loop. The data on its disk might get corrupted or lost. It is important to set up a discipline of keeping our work machine separate from our lab machine. Furthermore, it is good to have different login identities and credentials between these two environments. For example we wouldn't want a quirk in a beta environment causing corruption to an iCloud\\index{trademark!iCloud} resource we rely upon in our work environment. Unfortunately good \"data hygiene\" is mostly learnt after a painful data loss. To avoid this, it is best to have in place a good backup strategy before experimenting with lab environments, and potential unsafe configurations and software. One such strategy is to have all our code in a cloud service provider, such as GitHub\\index{trademark!GitHub}, have our documents and photos mirrored to iCloud\\index{trademark!iCloud}, have our desktop systems backed-up to Time Machine\\index{trademark!Time Machine} and the high value personal documents, license keys, etc. kept also on Write-Only DVD media. Terminology Here we adopt some standard terminology to describe our test environment. Item Description target debugee This system is being tested and inspected host debugger This system is driving the probing and analysis Required Hardware It is surprisingly helpful to collect a random collection of old computers, peripherals, and connectors. Sometimes an interesting vulnerability is seen only on old hardware, or a technique is only useable on old hardware. Variety is the key so that different types of lab setups are possible. In this tutorial we use a MacBook\\index{trademark!MacBook Pro} Pro target which has native USB-C interfaces. We connect a Thunderbolt USB-C to Thunderbolt adapter, and then connect a Thunderbolt Gigabit Ethernet Adapter to the Thunderbolt interface. Then we connect the ethernet cable to the host computer. The host computer is a Mac Mini based upon Apple Silicon. This choice of hardware comes from particular requirements. Direct thunderbolt communication When a system boots up, early on in its bring-up, it has few hardcoded facilities immediately at its disposal. The kernel will not have brought up its networking stack fully. This means for debug communication, it can only use a few hard coded facilities. The Kernel Development Kit from Apple documents what hardware is supported. It basically maps to either direct on-thunderbolt ethernet adapters or FireWire based connections. The FireWire\\index{trademark!FireWire} based communication is less flexible than Ethernet and is more of a legacy interface. So we shall ignore that option in this tutorial. We can use either the Gigabit Ethernet adapters or the 10 Gigabit Ethernet adapters (for Mac Pro\\index{trademark!Mac Pro}) from Apple. A USB Ethernet adapter will not work because it won't be able to route the debug communication packet onto that device. Note that most all-in-one adapters that connect to USB-C and offer a variety of ports including Ethernet will not work because the internal archictecture of these will have a USB Bus, and then there will be an affordable but lower performance Ethernet chip, such as a RealTek\\index{trademark!RealTek}. There are two problems here. Firstly the RealTek is not a supported chip for debug communication, and secondly the kernel cannot route the debug packet from the Thunderbolt bus onto the USB bus where the Ethernet chip resides. Notice that in our setup we first convert USB-C to Thunderbolt, and then convert Thunderbolt to Gigabit Ethernet. One advantage of our setup is that is it more flexible. Not all computers have native USB-C, but having two adapters means we have the flexibility to debug older computers. Using a laptop target One convenience arising from choosing a laptop as the debug target is that we can map the power key to halt the kernel and drop into the debugger. Also since the keyboard and trackpad are integrated, it means we have direct connectivity into the system. Required Software In order to do kernel debugging conveniently, we need a kernel with its debug symbols available so we can set symbolic breakpoints. We get the kernel version from the target machine as follows: target-mbp2018 # sw_vers ProductName: macOS ProductVersion: 11.3 BuildVersion: 20E5186d We need to get the matching Kernel Development Kit (KDK) from the Apple developer website @devapplemore We search for it using the build version, and it either it matches exactly, such as \"Kernel Debug Kit 11.3 build 20E5186d\", or it is not found. When it is not found, we are supposed to raise a developer support ticket to ask for it to be uploaded onto the Apple Website. An easier alternative is to just update our version of macOS to a version which is also shown on the @devapplemore website. The KDK software is needed both on the target (we shall install the development kernel on it), and on the host (we need it available so the debugger can reference it). An exact same KDK must be used on both target and host. Disable File Vault In order to manipulate the root file system when in Recovery Mode, we need to first disable File Vault. This is normally a background task and takes a while but is immediate on our MacBook Pro because its disk is managed by a T2 chip. (@disablefilevault) Use System Preferences > Security & Privacy > FileVault Unlock the padlock. Click Turn off FileVault Allow the system to process the decryption in the background. We must keep our system connected by AC power the whole time to achieve this. Disk information We shall do low level disk operations on our target machine, so first need to record the hardware device used for the root file system: target-mbp2018 # df / Filesystem 512-blocks Used Available Capacity iused ifree %iused Mounted on /dev/disk1s5s1 1953595632 59785248 469854808 12% 555854 9767422306 0% / This shows that in our case, we have APFS Container 1, Volume 5, Snapshot 1 representing the hard disk for the root file system. So our disk (ignoring the snapshot) is disk1s5 . Network information We shall be connecting to the target via the Thunderbolt Gigabit Ethernet, so we need to know the Ethernet port name used for it. First we connect our adapters to the machine, and then assuming there is only one Gigabit Ethernet port, we run the command: target-mbp2018 # ifconfig | grep -B6 1000baseT en9: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500 options=50b<RXCSUM,TXCSUM,VLAN_HWTAGGING,AV,CHANNEL_IO> ether 28:ec:95:03:b3:a6 inet6 fe80::18f5:dff5:a92b:d3ff%en9 prefixlen 64 secured scopeid 0x14 inet 169.254.203.131 netmask 0xffff0000 broadcast 169.254.255.255 nd6 options=201<PERFORMNUD,DAD> media: autoselect (1000baseT <full-duplex,flow-control,energy-efficient-ethernet>) So our network interface is en9 and our target machine appears on that interface as IP address 169.254.203.131 . Kernel Debug Flags When we setup our target for debugging, to head off potential boot-time issues, we need to establish what custom boot flags we shall use for booting and debugging. Technically speaking, these settings are tied to the particular kernel version we are debugging. The settings, however, change only occasionally. Kernel information is available from the Open Source archives published by Apple. (@appleopensource) We find that the release of such sources is delayed after the release of a given version of macOS. iOS kernel source is not published. However, it is macOS that is the most instructive because all the platforms are based on the same XNU kernel with just compile flag and device support differences. The convergence of the platforms at a low level allows the macOS platform to give good insights into all Apple platforms. We note, however, that the user experience is differentiated between the Apple platforms since the user needs to consume and experience the platform differently based upon the form factor of the system. These differences are mainly manifest in the library software layers on top of the XNU kernel. At the time of writing, the latest Apple Open Source release for macOS is 11.2 despite our target machine being 20E5186d. So we download its corresponding XNU kernel, xnu-7195.81.3 . The file osfmk/kern/debug.h describes the boot parameters that are available. /* Debug boot-args */ #define DB_HALT 0x1 //#define DB_PRT 0x2 -- obsolete #define DB_NMI 0x4 #define DB_KPRT 0x8 #define DB_KDB 0x10 #define DB_ARP 0x40 #define DB_KDP_BP_DIS 0x80 //#define DB_LOG_PI_SCRN 0x100 -- obsolete #define DB_KDP_GETC_ENA 0x200 #define DB_KERN_DUMP_ON_PANIC 0x400 /* Trigger core dump on panic*/ #define DB_KERN_DUMP_ON_NMI 0x800 /* Trigger core dump on NMI */ #define DB_DBG_POST_CORE 0x1000 /*Wait in debugger after NMI core */ #define DB_PANICLOG_DUMP 0x2000 /* Send paniclog on panic,not core*/ #define DB_REBOOT_POST_CORE 0x4000 /* Attempt to reboot after * post-panic crashdump/paniclog * dump. */ #define DB_NMI_BTN_ENA 0x8000 /* Enable button to directly trigger NMI */ /* 0x10000 was DB_PRT_KDEBUG (kprintf kdebug events), feature removed */ #define DB_DISABLE_LOCAL_CORE 0x20000 /* ignore local kernel core dump support */ #define DB_DISABLE_GZIP_CORE 0x40000 /* don't gzip kernel core dumps */ #define DB_DISABLE_CROSS_PANIC 0x80000 /* x86 only - don't trigger cross panics. Only * necessary to enable x86 kernel debugging on * configs with a dev-fused co-processor running * release bridgeOS. */ #define DB_REBOOT_ALWAYS 0x100000 /* Don't wait for debugger connection */ #define DB_DISABLE_STACKSHOT_TO_DISK 0x200000 /* Disable writing stackshot to local disk */ We require: DB_NMI : we want to enter the debugger upon a Non-Maskable Interrupt DB_ARP : we want the debugger communication to be over Address Resolution Protocol (in fact UDP packets) DB_NMI_BTN_ENA : we want the power button being tapped to generate a Non-Maskable Interrupt Hence we shall plan on supplying the debug boot argument debug=0x8044 Assumed Configuration For ease of explanation, we setup the following environmental variables matching our lab setup: TARGET=target-mbp2018 DISK=disk1s5 KERNEL=20E5186d KDK=KDK_11.3_20E5186d.kdk NETWORK_INTERFACE=en9 Software Installation We need to install our software first because later steps will utilise it from Recovery Mode. Host side software The host must install Xcode, and the specific KDK determined earlier. Target side software The target must install the KDK determined earlier. Lowering Security In order to debug our target we must lower the security settings. (@installxnu) We have three tasks to do whilst booted into Recovery Mode. Disable System Integrity Protection (SIP) We need to disable System Integrity Protection (SIP) using the Configurable Security Restrictions Utility ( csrutil ). Apple documentation @configsip tells us to: Boot into recovery mode (Command+R during boot) Launch a Terminal window from Utilities > Terminal . Run csrutil disable Quit the Terminal. Set No Boot Security We need to set boot security to No Security. (@startupsecurity) Launch Utilities > Startup Security Utility In section Secure Boot, set \"No Security\" Quit the Utility. Disable Authenticated Root Volume Security We need to disable authenticated Root Volume Security. (@rootvolsecurity) Launch a Terminal window from Utilities > Terminal . Run csrutil authenticated-root disable (Requires FileVault to be already disabled.) Quit the Terminal. Restart the computer. Configuring the Development Kernel Having rebooted our target machine, with the lowered security, we can adjust our machine to use the Development Kernel. This makes use of a kernel debugger easier since we have the kernel symbols for it that our debugger can use. Mount Read Write the Root File System export TARGET=target-mbp2018 DISK=disk1s5 KERNEL=20E5186d NETWORK_INTERFACE=en9 KDK=KDK_11.3_20E5186d.kdk mkdir /tmp/mnt sudo mount -o nobrowse -t apfs /dev/$DISK /tmp/mnt We should now have the root disk mounted Read Only and mounted Read Write target-mbp2018 # mount /dev/disk1s5s1 on / (apfs, sealed, local, read-only, journaled) . . /dev/disk1s5 on /private/tmp/mnt (apfs, sealed, local, journaled, nobrowse) Install the Development Kernel We place the development kernel on our system with: sudo cp /Library/Developer/KDKs/$KDK/System/Library/Kernels/kernel.devel opment /tmp/mnt/System/Library/Kernels Bless the Root File System We make our modified root file system bootable by the system by using the bless command. sudo bless --folder /tmp/mnt/System/Library/CoreServices --bootefi --create-snapshot Set boot parameters We need to set the boot parameters to use the development kernel. We also need to make it: Use the thunderbolt ethernet adapter ( kdp_match_name=en9 ), Not go to sleep when debugging ( wdt=-1 ), Verbose boot for debugging ( -v ) Use Power Key for entering the debugger over UDP packets ( debug=0x8044 ), In our lab configuration, this is done with: export NETWORK_INTERFACE=en9 sudo nvram boot-args=\"debug=0x8044 kdp_match_name=$NETWORK_INTERFACE wdt=-1 -v\" Target machine reboot Now we have everything in place. The target machine can be rebooted. If we watch it reboot closely, we can see that as it reboots, a lot of debug information will be printed onto the screen as part of the reboot. Host machine configuration At this point we have a host machine with Xcode, and the KDK installed on it. Only one further change is needed. The KDK comes with helper scripts to aid kernel debugging. These are tied to the Python 2 runtime environment, but Xcode LLDB Debugger uses Python 3 as the default. We need to switch to Python 2 as follows: defaults write com.apple.dt.lldb DefaultPythonVersion 2 Interactive debugging The host machine should be connected to the target machine. It should have the KDK installed on it. The Apple Spotlight feature will index it, and thus will be aware of the KDK symbols without it being explicitly told about them. On the target machine, we need to get the most recent IP address it has allocated for the Gigabit Ethernet interface en9 ( $NETWORK_INTERFACE ). target-mbp2018 # ifconfig en9 en9: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500 options=50b<RXCSUM,TXCSUM,VLAN_HWTAGGING,AV,CHANNEL_IO> ether 28:ec:95:03:b3:a6 inet6 fe80::14c8:8222:3ad9:82af%en9 prefixlen 64 secured scopeid 0x8 inet 169.254.136.48 netmask 0xffff0000 broadcast 169.254.255.255 nd6 options=201<PERFORMNUD,DAD> media: autoselect (1000baseT <full-duplex,flow-control,energy-efficient-ethernet>) status: active Here we have IP Address 169.254.136.48 . We now press the Power button on the target. It must be a normal press, not a tap, nor a long press. This will trigger the Non-Maskable Interrupt and freeze the machine, and it will then hunt for a kernel debugger connection. On the host machine, we run the following commands: lldb kdp-remote 169.254.136.48 At this point we will get a large information dump from the target machine, detailing the kernel extensions currently running: Version: Darwin Kernel Version 20.4.0: Wed Feb 10 23:06:18 PST 2021; root:xnu-7195.100.326.0.1~76/RELEASE_X86_64; UUID=04A94133-D929-3B0C-AF3D-907AF8BF4102; stext=0xffffff8010010000 Kernel UUID: 04A94133-D929-3B0C-AF3D-907AF8BF4102 Load Address: 0xffffff8010010000 Kernel slid 0xfe10000 in memory. Loaded kernel file /System/Volumes/Data/Library/Developer/KDKs/KDK_11.3_20E5186d.kd k/System/Library/Kernels/kernel warning: 'kernel' contains a debug script. To run this script in this debug session: command script import \"/System/Volumes/Data/Library/Developer/KDKs/KDK_11.3_20E5186d.k dk/System/Library/Kernels/kernel.dSYM/Contents/Resources/Python/k ernel.py\" To run all discovered debug scripts in this session: settings set target.load-script-from-symbol-file true Loading 176 kext modules -----.-------.------....-------------.-----.-------------------- -----.-----.-----------------------------------warning: 'IOGraphicsFamily' contains a debug script. To run this script in this debug session: command script import \"/Library/Developer/KDKs/KDK_11.3_20E5186d.kdk/System/Library/Ex tensions/IOGraphicsFamily.kext.dSYM/Contents/Resources/Python/IOG raphicsFamily.py\" To run all discovered debug scripts in this session: settings set target.load-script-from-symbol-file true .----.-------------..-------------.------------------------------ warning: 'IOGraphicsFamily' contains a debug script. To run this script in this debug session: command script import \"/Library/Developer/KDKs/KDK_11.3_20E5186d.kdk/System/Library/Ex tensions/IOGraphicsFamily.kext.dSYM/Contents/Resources/Python/IOG raphicsFamily.py\" To run all discovered debug scripts in this session: settings set target.load-script-from-symbol-file true done. Failed to load 161 of 176 kexts: com.apple.AGDCPluginDisplayMetrics 1B6E3133-91F9-3C8D-91E0-80843926DDE2 com.apple.AppleFSCompression.AppleFSCompressionTypeDataless 94BB56D9-8BF2-3088-8B4F-5B57DA797346 . . . com.apple.security.AppleImage4 2682857E-9FA5-3B36-A12C-104225C5EC80 com.apple.security.quarantine FAADAF70-7DDD-38AC-962B-64776C8FA3CD com.apple.security.sandbox 1947D7D5-5A3E-3F7D-83C1-641F2BB56D94 com.apple.vecLib.kext DE60F885-126D-3319-9683-CB4F0B8288A8 kernel was compiled with optimization - stepping may behave oddly; variables may not be available. Process 1 stopped * thread #1, stop reason = signal SIGSTOP frame #0: 0xffffff801008b363 kernel`DebuggerWithContext(reason=<unavailable>, ctx=<unavailable>, message=<unavailable>, debugger_options_mask=0) at debug.c:0 [opt] Target 0: (kernel) stopped. As instructed, we should run the debug scripts: settings set target.load-script-from-symbol-file true So long as we have already set the Python version to 2 (earlier) we should see the scripts run successfully: Loading kernel debugging from /System/Volumes/Data/Library/Developer/KDKs/KDK_11.3_20E5186d.kd k/System/Library/Kernels/kernel.dSYM/Contents/Resources/Python/ke rnel.py LLDB version lldb-1200.0.44.2 Apple Swift version 5.3.2 (swiftlang-1200.0.45 clang-1200.0.32.28) settings set target.process.python-os-plugin-path \"/System/Volumes/Data/Library/Developer/KDKs/KDK_11.3_20E5186d.k dk/System/Library/Kernels/kernel.dSYM/Contents/Resources/Python/l ldbmacros/core/operating_system.py\" Target arch: x86_64 Instantiating threads completely from saved state in memory. settings set target.trap-handler-names hndl_allintrs hndl_alltraps trap_from_kernel hndl_double_fault hndl_machine_check _fleh_prefabt _ExceptionVectorsBase _ExceptionVectorsTable _fleh_undef _fleh_dataabt _fleh_irq _fleh_decirq _fleh_fiq_generic _fleh_dec command script import \"/System/Volumes/Data/Library/Developer/KDKs/KDK_11.3_20E5186d.k dk/System/Library/Kernels/kernel.dSYM/Contents/Resources/Python/l ldbmacros/xnu.py\" xnu debug macros loaded successfully. Run showlldbtypesummaries to enable type summaries. settings set target.process.optimization-warnings false Simple register writing test To prove to ourselves we have a live debuggable kernel we can run the following commands from llvm on the host. First we get the backtrace from where we've interrupted the Operating System: (lldb) bt * thread #2, name = '0xffffff86a4828898', queue = '0x0', stop reason = signal SIGSTOP * frame #0: 0xffffff801008b363 kernel`DebuggerWithContext(reason=<unavailable>, ctx=<unavailable>, message=<unavailable>, debugger_options_mask=0) at debug.c:0 [opt] frame #1: 0xffffff80111a68da frame #2: 0xffffff80107eeba1 kernel`IOFilterInterruptEventSource::normalInterruptOccurred(thi s=0xffffff93712ca880, (null)=<unavailable>, (null)=<unavailable>, (null)=<unavailable>) at IOFilterInterruptEventSource.cpp:236:15 [opt] frame #3: 0xffffff8011130c51 frame #4: 0xffffff80111505a7 frame #5: 0xffffff801115496d frame #6: 0xffffff8010815feb kernel`IOSharedInterruptController::handleInterrupt(this=0xfffff f937101f000, (null)=<unavailable>, nub=0xffffff937113ad80, (null)=<unavailable>) at IOInterruptController.cpp:830:5 [opt] frame #7: 0xffffff80111bfa77 frame #8: 0xffffff8011126354 frame #9: 0xffffff801112f2fd frame #10: 0xffffff80101c0ced kernel`interrupt [inlined] get_preemption_level at cpu_data.h:430:21 [opt] frame #11: 0xffffff801002fbdd kernel`hndl_allintrs + 285 frame #12: 0xffffff80101c39ba kernel`machine_idle at pmCPU.c:235:1 [opt] frame #13: 0xffffff80100b32c9 kernel`processor_idle(thread=0x0000000000000000, processor=0xffffff8010ea9a40) at sched_prim.c:5346:3 [opt] frame #14: 0xffffff80100b3498 kernel`idle_thread(parameter=<unavailable>, result=<unavailable>) at sched_prim.c:5436:24 [opt] frame #15: 0xffffff801002f13e kernel`call_continuation + 46 Next we read the current registers: (lldb) register read --all General Purpose Registers: rax = 0x0000000000000000 rbx = 0x0000000000000000 rcx = 0x0000000000000000 rdx = 0xffffff80111a6fb5 rdi = 0x0000000000000000 rsi = 0x0000000000000001 rbp = 0xffffffa062996de0 rsp = 0xffffffa062996db0 r8 = 0x0000000000000000 r9 = 0x0000000000000066 r10 = 0xffffff8011196720 r11 = 0xffffff8011196728 r12 = 0x0000000000000046 r13 = 0xffffff8010ea9a00 r14 = 0x0000000000000000 r15 = 0x0000000000000001 rip = 0xffffff801008b363 kernel`DebuggerWithContext + 275 at debug.c rflags = 0x0000000000000046 cs = 0x0000000000000008 fs = 0x00000000ffff0000 gs = 0x0000000062990000 Floating Point Registers: fcw = 0x0000 fsw = 0x0000 . . . Next we write AAA.. into a register: (lldb) register write R8 0x4141414141414141 (lldb) register read --all General Purpose Registers: rax = 0x0000000000000000 rbx = 0x0000000000000000 rcx = 0x0000000000000000 rdx = 0xffffff80111a6fb5 rdi = 0x0000000000000000 rsi = 0x0000000000000001 rbp = 0xffffffa062996de0 rsp = 0xffffffa062996db0 r8 = 0x4141414141414141 r9 = 0x0000000000000066 . . Next we store the original values in the R8 register: (lldb) register write R8 0x0","title":"Booting a Development Kernel"},{"location":"BootingDevelopmentKernel/#booting-and-exploring-a-development-kernel","text":"This section is a practical tutorial on how to setup a system for interactive kernel level debugging. At a high level, this is our workflow:","title":"Booting and exploring a Development Kernel"},{"location":"BootingDevelopmentKernel/#data-safety","text":"Experimenting with kernels can be like playing with fire. The target machine must be throwaway; it might end up no longer booting, or be stuck in a boot loop. The data on its disk might get corrupted or lost. It is important to set up a discipline of keeping our work machine separate from our lab machine. Furthermore, it is good to have different login identities and credentials between these two environments. For example we wouldn't want a quirk in a beta environment causing corruption to an iCloud\\index{trademark!iCloud} resource we rely upon in our work environment. Unfortunately good \"data hygiene\" is mostly learnt after a painful data loss. To avoid this, it is best to have in place a good backup strategy before experimenting with lab environments, and potential unsafe configurations and software. One such strategy is to have all our code in a cloud service provider, such as GitHub\\index{trademark!GitHub}, have our documents and photos mirrored to iCloud\\index{trademark!iCloud}, have our desktop systems backed-up to Time Machine\\index{trademark!Time Machine} and the high value personal documents, license keys, etc. kept also on Write-Only DVD media.","title":"Data Safety"},{"location":"BootingDevelopmentKernel/#terminology","text":"Here we adopt some standard terminology to describe our test environment. Item Description target debugee This system is being tested and inspected host debugger This system is driving the probing and analysis","title":"Terminology"},{"location":"BootingDevelopmentKernel/#required-hardware","text":"It is surprisingly helpful to collect a random collection of old computers, peripherals, and connectors. Sometimes an interesting vulnerability is seen only on old hardware, or a technique is only useable on old hardware. Variety is the key so that different types of lab setups are possible. In this tutorial we use a MacBook\\index{trademark!MacBook Pro} Pro target which has native USB-C interfaces. We connect a Thunderbolt USB-C to Thunderbolt adapter, and then connect a Thunderbolt Gigabit Ethernet Adapter to the Thunderbolt interface. Then we connect the ethernet cable to the host computer. The host computer is a Mac Mini based upon Apple Silicon. This choice of hardware comes from particular requirements.","title":"Required Hardware"},{"location":"BootingDevelopmentKernel/#direct-thunderbolt-communication","text":"When a system boots up, early on in its bring-up, it has few hardcoded facilities immediately at its disposal. The kernel will not have brought up its networking stack fully. This means for debug communication, it can only use a few hard coded facilities. The Kernel Development Kit from Apple documents what hardware is supported. It basically maps to either direct on-thunderbolt ethernet adapters or FireWire based connections. The FireWire\\index{trademark!FireWire} based communication is less flexible than Ethernet and is more of a legacy interface. So we shall ignore that option in this tutorial. We can use either the Gigabit Ethernet adapters or the 10 Gigabit Ethernet adapters (for Mac Pro\\index{trademark!Mac Pro}) from Apple. A USB Ethernet adapter will not work because it won't be able to route the debug communication packet onto that device. Note that most all-in-one adapters that connect to USB-C and offer a variety of ports including Ethernet will not work because the internal archictecture of these will have a USB Bus, and then there will be an affordable but lower performance Ethernet chip, such as a RealTek\\index{trademark!RealTek}. There are two problems here. Firstly the RealTek is not a supported chip for debug communication, and secondly the kernel cannot route the debug packet from the Thunderbolt bus onto the USB bus where the Ethernet chip resides. Notice that in our setup we first convert USB-C to Thunderbolt, and then convert Thunderbolt to Gigabit Ethernet. One advantage of our setup is that is it more flexible. Not all computers have native USB-C, but having two adapters means we have the flexibility to debug older computers.","title":"Direct thunderbolt communication"},{"location":"BootingDevelopmentKernel/#using-a-laptop-target","text":"One convenience arising from choosing a laptop as the debug target is that we can map the power key to halt the kernel and drop into the debugger. Also since the keyboard and trackpad are integrated, it means we have direct connectivity into the system.","title":"Using a laptop target"},{"location":"BootingDevelopmentKernel/#required-software","text":"In order to do kernel debugging conveniently, we need a kernel with its debug symbols available so we can set symbolic breakpoints. We get the kernel version from the target machine as follows: target-mbp2018 # sw_vers ProductName: macOS ProductVersion: 11.3 BuildVersion: 20E5186d We need to get the matching Kernel Development Kit (KDK) from the Apple developer website @devapplemore We search for it using the build version, and it either it matches exactly, such as \"Kernel Debug Kit 11.3 build 20E5186d\", or it is not found. When it is not found, we are supposed to raise a developer support ticket to ask for it to be uploaded onto the Apple Website. An easier alternative is to just update our version of macOS to a version which is also shown on the @devapplemore website. The KDK software is needed both on the target (we shall install the development kernel on it), and on the host (we need it available so the debugger can reference it). An exact same KDK must be used on both target and host.","title":"Required Software"},{"location":"BootingDevelopmentKernel/#disable-file-vault","text":"In order to manipulate the root file system when in Recovery Mode, we need to first disable File Vault. This is normally a background task and takes a while but is immediate on our MacBook Pro because its disk is managed by a T2 chip. (@disablefilevault) Use System Preferences > Security & Privacy > FileVault Unlock the padlock. Click Turn off FileVault Allow the system to process the decryption in the background. We must keep our system connected by AC power the whole time to achieve this.","title":"Disable File Vault"},{"location":"BootingDevelopmentKernel/#disk-information","text":"We shall do low level disk operations on our target machine, so first need to record the hardware device used for the root file system: target-mbp2018 # df / Filesystem 512-blocks Used Available Capacity iused ifree %iused Mounted on /dev/disk1s5s1 1953595632 59785248 469854808 12% 555854 9767422306 0% / This shows that in our case, we have APFS Container 1, Volume 5, Snapshot 1 representing the hard disk for the root file system. So our disk (ignoring the snapshot) is disk1s5 .","title":"Disk information"},{"location":"BootingDevelopmentKernel/#network-information","text":"We shall be connecting to the target via the Thunderbolt Gigabit Ethernet, so we need to know the Ethernet port name used for it. First we connect our adapters to the machine, and then assuming there is only one Gigabit Ethernet port, we run the command: target-mbp2018 # ifconfig | grep -B6 1000baseT en9: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500 options=50b<RXCSUM,TXCSUM,VLAN_HWTAGGING,AV,CHANNEL_IO> ether 28:ec:95:03:b3:a6 inet6 fe80::18f5:dff5:a92b:d3ff%en9 prefixlen 64 secured scopeid 0x14 inet 169.254.203.131 netmask 0xffff0000 broadcast 169.254.255.255 nd6 options=201<PERFORMNUD,DAD> media: autoselect (1000baseT <full-duplex,flow-control,energy-efficient-ethernet>) So our network interface is en9 and our target machine appears on that interface as IP address 169.254.203.131 .","title":"Network information"},{"location":"BootingDevelopmentKernel/#kernel-debug-flags","text":"When we setup our target for debugging, to head off potential boot-time issues, we need to establish what custom boot flags we shall use for booting and debugging. Technically speaking, these settings are tied to the particular kernel version we are debugging. The settings, however, change only occasionally. Kernel information is available from the Open Source archives published by Apple. (@appleopensource) We find that the release of such sources is delayed after the release of a given version of macOS. iOS kernel source is not published. However, it is macOS that is the most instructive because all the platforms are based on the same XNU kernel with just compile flag and device support differences. The convergence of the platforms at a low level allows the macOS platform to give good insights into all Apple platforms. We note, however, that the user experience is differentiated between the Apple platforms since the user needs to consume and experience the platform differently based upon the form factor of the system. These differences are mainly manifest in the library software layers on top of the XNU kernel. At the time of writing, the latest Apple Open Source release for macOS is 11.2 despite our target machine being 20E5186d. So we download its corresponding XNU kernel, xnu-7195.81.3 . The file osfmk/kern/debug.h describes the boot parameters that are available. /* Debug boot-args */ #define DB_HALT 0x1 //#define DB_PRT 0x2 -- obsolete #define DB_NMI 0x4 #define DB_KPRT 0x8 #define DB_KDB 0x10 #define DB_ARP 0x40 #define DB_KDP_BP_DIS 0x80 //#define DB_LOG_PI_SCRN 0x100 -- obsolete #define DB_KDP_GETC_ENA 0x200 #define DB_KERN_DUMP_ON_PANIC 0x400 /* Trigger core dump on panic*/ #define DB_KERN_DUMP_ON_NMI 0x800 /* Trigger core dump on NMI */ #define DB_DBG_POST_CORE 0x1000 /*Wait in debugger after NMI core */ #define DB_PANICLOG_DUMP 0x2000 /* Send paniclog on panic,not core*/ #define DB_REBOOT_POST_CORE 0x4000 /* Attempt to reboot after * post-panic crashdump/paniclog * dump. */ #define DB_NMI_BTN_ENA 0x8000 /* Enable button to directly trigger NMI */ /* 0x10000 was DB_PRT_KDEBUG (kprintf kdebug events), feature removed */ #define DB_DISABLE_LOCAL_CORE 0x20000 /* ignore local kernel core dump support */ #define DB_DISABLE_GZIP_CORE 0x40000 /* don't gzip kernel core dumps */ #define DB_DISABLE_CROSS_PANIC 0x80000 /* x86 only - don't trigger cross panics. Only * necessary to enable x86 kernel debugging on * configs with a dev-fused co-processor running * release bridgeOS. */ #define DB_REBOOT_ALWAYS 0x100000 /* Don't wait for debugger connection */ #define DB_DISABLE_STACKSHOT_TO_DISK 0x200000 /* Disable writing stackshot to local disk */ We require: DB_NMI : we want to enter the debugger upon a Non-Maskable Interrupt DB_ARP : we want the debugger communication to be over Address Resolution Protocol (in fact UDP packets) DB_NMI_BTN_ENA : we want the power button being tapped to generate a Non-Maskable Interrupt Hence we shall plan on supplying the debug boot argument debug=0x8044","title":"Kernel Debug Flags"},{"location":"BootingDevelopmentKernel/#assumed-configuration","text":"For ease of explanation, we setup the following environmental variables matching our lab setup: TARGET=target-mbp2018 DISK=disk1s5 KERNEL=20E5186d KDK=KDK_11.3_20E5186d.kdk NETWORK_INTERFACE=en9","title":"Assumed Configuration"},{"location":"BootingDevelopmentKernel/#software-installation","text":"We need to install our software first because later steps will utilise it from Recovery Mode.","title":"Software Installation"},{"location":"BootingDevelopmentKernel/#host-side-software","text":"The host must install Xcode, and the specific KDK determined earlier.","title":"Host side software"},{"location":"BootingDevelopmentKernel/#target-side-software","text":"The target must install the KDK determined earlier.","title":"Target side software"},{"location":"BootingDevelopmentKernel/#lowering-security","text":"In order to debug our target we must lower the security settings. (@installxnu) We have three tasks to do whilst booted into Recovery Mode.","title":"Lowering Security"},{"location":"BootingDevelopmentKernel/#disable-system-integrity-protection-sip","text":"We need to disable System Integrity Protection (SIP) using the Configurable Security Restrictions Utility ( csrutil ). Apple documentation @configsip tells us to: Boot into recovery mode (Command+R during boot) Launch a Terminal window from Utilities > Terminal . Run csrutil disable Quit the Terminal.","title":"Disable System Integrity Protection (SIP)"},{"location":"BootingDevelopmentKernel/#set-no-boot-security","text":"We need to set boot security to No Security. (@startupsecurity) Launch Utilities > Startup Security Utility In section Secure Boot, set \"No Security\" Quit the Utility.","title":"Set No Boot Security"},{"location":"BootingDevelopmentKernel/#disable-authenticated-root-volume-security","text":"We need to disable authenticated Root Volume Security. (@rootvolsecurity) Launch a Terminal window from Utilities > Terminal . Run csrutil authenticated-root disable (Requires FileVault to be already disabled.) Quit the Terminal. Restart the computer.","title":"Disable Authenticated Root Volume Security"},{"location":"BootingDevelopmentKernel/#configuring-the-development-kernel","text":"Having rebooted our target machine, with the lowered security, we can adjust our machine to use the Development Kernel. This makes use of a kernel debugger easier since we have the kernel symbols for it that our debugger can use.","title":"Configuring the Development Kernel"},{"location":"BootingDevelopmentKernel/#mount-read-write-the-root-file-system","text":"export TARGET=target-mbp2018 DISK=disk1s5 KERNEL=20E5186d NETWORK_INTERFACE=en9 KDK=KDK_11.3_20E5186d.kdk mkdir /tmp/mnt sudo mount -o nobrowse -t apfs /dev/$DISK /tmp/mnt We should now have the root disk mounted Read Only and mounted Read Write target-mbp2018 # mount /dev/disk1s5s1 on / (apfs, sealed, local, read-only, journaled) . . /dev/disk1s5 on /private/tmp/mnt (apfs, sealed, local, journaled, nobrowse)","title":"Mount Read Write the Root File System"},{"location":"BootingDevelopmentKernel/#install-the-development-kernel","text":"We place the development kernel on our system with: sudo cp /Library/Developer/KDKs/$KDK/System/Library/Kernels/kernel.devel opment /tmp/mnt/System/Library/Kernels","title":"Install the Development Kernel"},{"location":"BootingDevelopmentKernel/#bless-the-root-file-system","text":"We make our modified root file system bootable by the system by using the bless command. sudo bless --folder /tmp/mnt/System/Library/CoreServices --bootefi --create-snapshot","title":"Bless the Root File System"},{"location":"BootingDevelopmentKernel/#set-boot-parameters","text":"We need to set the boot parameters to use the development kernel. We also need to make it: Use the thunderbolt ethernet adapter ( kdp_match_name=en9 ), Not go to sleep when debugging ( wdt=-1 ), Verbose boot for debugging ( -v ) Use Power Key for entering the debugger over UDP packets ( debug=0x8044 ), In our lab configuration, this is done with: export NETWORK_INTERFACE=en9 sudo nvram boot-args=\"debug=0x8044 kdp_match_name=$NETWORK_INTERFACE wdt=-1 -v\"","title":"Set boot parameters"},{"location":"BootingDevelopmentKernel/#target-machine-reboot","text":"Now we have everything in place. The target machine can be rebooted. If we watch it reboot closely, we can see that as it reboots, a lot of debug information will be printed onto the screen as part of the reboot.","title":"Target machine reboot"},{"location":"BootingDevelopmentKernel/#host-machine-configuration","text":"At this point we have a host machine with Xcode, and the KDK installed on it. Only one further change is needed. The KDK comes with helper scripts to aid kernel debugging. These are tied to the Python 2 runtime environment, but Xcode LLDB Debugger uses Python 3 as the default. We need to switch to Python 2 as follows: defaults write com.apple.dt.lldb DefaultPythonVersion 2","title":"Host machine configuration"},{"location":"BootingDevelopmentKernel/#interactive-debugging","text":"The host machine should be connected to the target machine. It should have the KDK installed on it. The Apple Spotlight feature will index it, and thus will be aware of the KDK symbols without it being explicitly told about them. On the target machine, we need to get the most recent IP address it has allocated for the Gigabit Ethernet interface en9 ( $NETWORK_INTERFACE ). target-mbp2018 # ifconfig en9 en9: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500 options=50b<RXCSUM,TXCSUM,VLAN_HWTAGGING,AV,CHANNEL_IO> ether 28:ec:95:03:b3:a6 inet6 fe80::14c8:8222:3ad9:82af%en9 prefixlen 64 secured scopeid 0x8 inet 169.254.136.48 netmask 0xffff0000 broadcast 169.254.255.255 nd6 options=201<PERFORMNUD,DAD> media: autoselect (1000baseT <full-duplex,flow-control,energy-efficient-ethernet>) status: active Here we have IP Address 169.254.136.48 . We now press the Power button on the target. It must be a normal press, not a tap, nor a long press. This will trigger the Non-Maskable Interrupt and freeze the machine, and it will then hunt for a kernel debugger connection. On the host machine, we run the following commands: lldb kdp-remote 169.254.136.48 At this point we will get a large information dump from the target machine, detailing the kernel extensions currently running: Version: Darwin Kernel Version 20.4.0: Wed Feb 10 23:06:18 PST 2021; root:xnu-7195.100.326.0.1~76/RELEASE_X86_64; UUID=04A94133-D929-3B0C-AF3D-907AF8BF4102; stext=0xffffff8010010000 Kernel UUID: 04A94133-D929-3B0C-AF3D-907AF8BF4102 Load Address: 0xffffff8010010000 Kernel slid 0xfe10000 in memory. Loaded kernel file /System/Volumes/Data/Library/Developer/KDKs/KDK_11.3_20E5186d.kd k/System/Library/Kernels/kernel warning: 'kernel' contains a debug script. To run this script in this debug session: command script import \"/System/Volumes/Data/Library/Developer/KDKs/KDK_11.3_20E5186d.k dk/System/Library/Kernels/kernel.dSYM/Contents/Resources/Python/k ernel.py\" To run all discovered debug scripts in this session: settings set target.load-script-from-symbol-file true Loading 176 kext modules -----.-------.------....-------------.-----.-------------------- -----.-----.-----------------------------------warning: 'IOGraphicsFamily' contains a debug script. To run this script in this debug session: command script import \"/Library/Developer/KDKs/KDK_11.3_20E5186d.kdk/System/Library/Ex tensions/IOGraphicsFamily.kext.dSYM/Contents/Resources/Python/IOG raphicsFamily.py\" To run all discovered debug scripts in this session: settings set target.load-script-from-symbol-file true .----.-------------..-------------.------------------------------ warning: 'IOGraphicsFamily' contains a debug script. To run this script in this debug session: command script import \"/Library/Developer/KDKs/KDK_11.3_20E5186d.kdk/System/Library/Ex tensions/IOGraphicsFamily.kext.dSYM/Contents/Resources/Python/IOG raphicsFamily.py\" To run all discovered debug scripts in this session: settings set target.load-script-from-symbol-file true done. Failed to load 161 of 176 kexts: com.apple.AGDCPluginDisplayMetrics 1B6E3133-91F9-3C8D-91E0-80843926DDE2 com.apple.AppleFSCompression.AppleFSCompressionTypeDataless 94BB56D9-8BF2-3088-8B4F-5B57DA797346 . . . com.apple.security.AppleImage4 2682857E-9FA5-3B36-A12C-104225C5EC80 com.apple.security.quarantine FAADAF70-7DDD-38AC-962B-64776C8FA3CD com.apple.security.sandbox 1947D7D5-5A3E-3F7D-83C1-641F2BB56D94 com.apple.vecLib.kext DE60F885-126D-3319-9683-CB4F0B8288A8 kernel was compiled with optimization - stepping may behave oddly; variables may not be available. Process 1 stopped * thread #1, stop reason = signal SIGSTOP frame #0: 0xffffff801008b363 kernel`DebuggerWithContext(reason=<unavailable>, ctx=<unavailable>, message=<unavailable>, debugger_options_mask=0) at debug.c:0 [opt] Target 0: (kernel) stopped. As instructed, we should run the debug scripts: settings set target.load-script-from-symbol-file true So long as we have already set the Python version to 2 (earlier) we should see the scripts run successfully: Loading kernel debugging from /System/Volumes/Data/Library/Developer/KDKs/KDK_11.3_20E5186d.kd k/System/Library/Kernels/kernel.dSYM/Contents/Resources/Python/ke rnel.py LLDB version lldb-1200.0.44.2 Apple Swift version 5.3.2 (swiftlang-1200.0.45 clang-1200.0.32.28) settings set target.process.python-os-plugin-path \"/System/Volumes/Data/Library/Developer/KDKs/KDK_11.3_20E5186d.k dk/System/Library/Kernels/kernel.dSYM/Contents/Resources/Python/l ldbmacros/core/operating_system.py\" Target arch: x86_64 Instantiating threads completely from saved state in memory. settings set target.trap-handler-names hndl_allintrs hndl_alltraps trap_from_kernel hndl_double_fault hndl_machine_check _fleh_prefabt _ExceptionVectorsBase _ExceptionVectorsTable _fleh_undef _fleh_dataabt _fleh_irq _fleh_decirq _fleh_fiq_generic _fleh_dec command script import \"/System/Volumes/Data/Library/Developer/KDKs/KDK_11.3_20E5186d.k dk/System/Library/Kernels/kernel.dSYM/Contents/Resources/Python/l ldbmacros/xnu.py\" xnu debug macros loaded successfully. Run showlldbtypesummaries to enable type summaries. settings set target.process.optimization-warnings false","title":"Interactive debugging"},{"location":"BootingDevelopmentKernel/#simple-register-writing-test","text":"To prove to ourselves we have a live debuggable kernel we can run the following commands from llvm on the host. First we get the backtrace from where we've interrupted the Operating System: (lldb) bt * thread #2, name = '0xffffff86a4828898', queue = '0x0', stop reason = signal SIGSTOP * frame #0: 0xffffff801008b363 kernel`DebuggerWithContext(reason=<unavailable>, ctx=<unavailable>, message=<unavailable>, debugger_options_mask=0) at debug.c:0 [opt] frame #1: 0xffffff80111a68da frame #2: 0xffffff80107eeba1 kernel`IOFilterInterruptEventSource::normalInterruptOccurred(thi s=0xffffff93712ca880, (null)=<unavailable>, (null)=<unavailable>, (null)=<unavailable>) at IOFilterInterruptEventSource.cpp:236:15 [opt] frame #3: 0xffffff8011130c51 frame #4: 0xffffff80111505a7 frame #5: 0xffffff801115496d frame #6: 0xffffff8010815feb kernel`IOSharedInterruptController::handleInterrupt(this=0xfffff f937101f000, (null)=<unavailable>, nub=0xffffff937113ad80, (null)=<unavailable>) at IOInterruptController.cpp:830:5 [opt] frame #7: 0xffffff80111bfa77 frame #8: 0xffffff8011126354 frame #9: 0xffffff801112f2fd frame #10: 0xffffff80101c0ced kernel`interrupt [inlined] get_preemption_level at cpu_data.h:430:21 [opt] frame #11: 0xffffff801002fbdd kernel`hndl_allintrs + 285 frame #12: 0xffffff80101c39ba kernel`machine_idle at pmCPU.c:235:1 [opt] frame #13: 0xffffff80100b32c9 kernel`processor_idle(thread=0x0000000000000000, processor=0xffffff8010ea9a40) at sched_prim.c:5346:3 [opt] frame #14: 0xffffff80100b3498 kernel`idle_thread(parameter=<unavailable>, result=<unavailable>) at sched_prim.c:5436:24 [opt] frame #15: 0xffffff801002f13e kernel`call_continuation + 46 Next we read the current registers: (lldb) register read --all General Purpose Registers: rax = 0x0000000000000000 rbx = 0x0000000000000000 rcx = 0x0000000000000000 rdx = 0xffffff80111a6fb5 rdi = 0x0000000000000000 rsi = 0x0000000000000001 rbp = 0xffffffa062996de0 rsp = 0xffffffa062996db0 r8 = 0x0000000000000000 r9 = 0x0000000000000066 r10 = 0xffffff8011196720 r11 = 0xffffff8011196728 r12 = 0x0000000000000046 r13 = 0xffffff8010ea9a00 r14 = 0x0000000000000000 r15 = 0x0000000000000001 rip = 0xffffff801008b363 kernel`DebuggerWithContext + 275 at debug.c rflags = 0x0000000000000046 cs = 0x0000000000000008 fs = 0x00000000ffff0000 gs = 0x0000000062990000 Floating Point Registers: fcw = 0x0000 fsw = 0x0000 . . . Next we write AAA.. into a register: (lldb) register write R8 0x4141414141414141 (lldb) register read --all General Purpose Registers: rax = 0x0000000000000000 rbx = 0x0000000000000000 rcx = 0x0000000000000000 rdx = 0xffffff80111a6fb5 rdi = 0x0000000000000000 rsi = 0x0000000000000001 rbp = 0xffffffa062996de0 rsp = 0xffffffa062996db0 r8 = 0x4141414141414141 r9 = 0x0000000000000066 . . Next we store the original values in the R8 register: (lldb) register write R8 0x0","title":"Simple register writing test"},{"location":"Hammer/","text":"The Hammer When studying past exploits it can feel like our brain has been hit by a hammer. It is because most exploit discussions work on the basis that we have had an apprenticeship on all the underlying techniques, and that only that final layer needs explanation. This approach is understandable from the writer's perspective. If we are a researcher we will naturally seek out underlying technologies, documentation and reading materials as part of our research journey. The writer's audience will be such researchers. So the writer will not dwell on the supporting techniques and technologies. Since iOS and macOS use many niche technologies, or use standard techniques with some Apple ecosystem unique twists, it is not so easy to do our background reading. In this chapter we shall look at an exploit write-up. Our purpose is not to understand the exploit as such, but to survey the techniques and technologies at play. It will provide us the motivation to explore such items in subsequent chapters knowing that this knowledge will then help us circle back and understand the originally presented exploit. Getting Exploits Exploits can be downloaded from the Exploit Database Git Repository . This is a valuable resource and one we shall often refer to. The exploit database has a search tool, searchsploit . If we install searchsploit from Exploit Database Git Repository and configure our ~/.searchsploit_rc file then we can easily look up exploits. This is a search for items matching ios and dos : searchsploit ios dos | less ------------------------------- --------------------------------- Exploit Title | Path ------------------------------- --------------------------------- Apple iOS - Kernel Stack Memor | ios/dos/45649.txt Apple iOS 1.1.2 - Remote Denia | hardware/dos/4978.html Apple iOS 1.1.4/2.0 / iPod 1.1 | hardware/dos/32341.html Apple iOS 11.2.5 / watchOS 4.2 | multiple/dos/44215.m Apple iOS 4.0.3 - DPAP Server | ios/dos/5151.pl Apple iOS 5.1.1 Safari Browser | ios/dos/18931.rb Apple iOS < 10.3.2 - Notificat | ios/dos/42014.txt Apple iOS Kernel - Use-After-F | ios/dos/45652.c Apple iOS Mobile Safari - Memo | ios/dos/31057.html Apple iOS Safari - 'decodeURI' | hardware/dos/15794.php Apple iOS Safari - 'decodeURIC | hardware/dos/15796.php Apple iOS Safari - 'JS .' Remo | hardware/dos/15805.php Apple iOS Safari - Bad 'VML' R | ios/dos/11890.txt Apple iOS Safari - body alink | hardware/dos/15792.php Apple iOS Safari - Remote Deni | ios/dos/11891.txt Apple iOS/macOS - Kernel Memor | multiple/dos/45651.c Apple iOS/macOS - Sandbox Esca | multiple/dos/45648.txt Apple iOS/macOS - Sandbox Esca | multiple/dos/45650.txt Apple Mac OSX - IOSCSIPeripher | osx/dos/39376.c Exploits can be searched for, downloaded, and then explored. Each exploit has a number associated with it, known as the EDB-ID . copyin_leak Exploit 45649 This program allows a user program to get the kernel to expose memory values it should not be able to see. In that sense it is an information disclosure \"leak\". The kernel routine used to do this is copyin hence it has been called a copyin_leak . The following command places a local copy of the exploit write-up in our local directory, known as the mirror (-m) command. # searchsploit -m 45649 Exploit: Apple iOS - Kernel Stack Memory Disclosure due to Failure to Check copyin Return Value URL: https://www.exploit-db.com/exploits/45649 Path: /Users/faisalm/dev/exploitdb/exploits/ios/dos/45649.txt File Type: ASCII text, with CRLF line terminators Copied to: /Users/faisalm/dev/scratch/45649.txt From looking at the text file, we find we can download the actual Proof of Concept (POC) from a Git Hub web address. This provides us an app to run on simulator or on an iDevice. This POC has been tested on iPod touch (7th generation) iOS 13.5 (17F75) and iPod touch (7th generation) simulator iOS 14.4 (18D46) copyin_leak write-up Here is the verbatim text for the write-up of this leak. The purpose for including it is to show the \"level\" at which exploit research is aimed at. The main aim of this book is to bring ourselves up to the same level so we can appreciate this piece of research, and then move forwards onto exploring and finding our own vulnerabilities. Here's a code snippet from sleh.c with the second level exception handler for undefined instruction exceptions: static void handle_uncategorized ( arm_saved_state_t * state , boolean_t instrLen2 ) { exception_type_t exception = EXC_BAD_INSTRUCTION ; mach_exception_data_type_t codes [ 2 ] = { EXC_ARM_UNDEFINED }; mach_msg_type_number_t numcodes = 2 ; uint32_t instr ; // <------- (a) if ( instrLen2 ) { uint16_t instr16 ; COPYIN ( get_saved_state_pc ( state ), ( char * ) & instr16 , sizeof ( instr16 )); instr = instr16 ; } else { COPYIN ( get_saved_state_pc ( state ), ( char * ) & instr , sizeof ( instr )); <------- ( b ) } .... else { codes [ 1 ] = instr ; <------ ( c ) } } exception_triage ( exception , codes , numcodes ); <-------- ( d ) At (a) the uint32_t instr is declared uninitialized on the stack. At (b) the code tries to copyin the bytes of the exception-causing instruction from userspace note that the COPYIN macro doesn't itself check the return value of copyin, it just calls it. At (c) instr is assigned to codes[1] , which at (d) is passed to exception_triage . That codes array will eventually end up being sent in an exception mach message. The bug is that we can force copyin to fail by unmapping the page containing the undefined instruction while it's being handled. (I tried to do this with XO memory but the kernel seems to be able to copyin that just fine.) This PoC has an undefined instruction (0xdeadbeef) on its own page and spins up a thread to keep switching the protection of that page between VM_PROT_NONE and VM_PROT_READ|VM_PROT_EXECUTE . We then keep spinning up threads which try to execute that undefined instruction. If the race windows align the thread executes the undefined instruction but when the sleh code tries to copyin the page is unmapped, the copying fails and the exception message we get has stale stack memory. This PoC just demonstrates that we do get values which aren't 0xdeadbeef in there for the EXC_ARM_UNDEFINED type. We'd have to do a bit more fiddling to work out how to get something specific there. Note that there are lots of other unchecked COPYIN 's in sleh.c (eg when userspace tries to access a system register not allowed for EL0) and these seem to have the same issue. tested on iPod Touch 6g running 11.3.1, but looking at the kernelcache it seems to still be there in iOS 12. Proof of Concept: https://github.com/offensive-security/exploitdb-bin-sploits/raw/m aster/bin-sploits/45649.zip That's the end of the write-up. It covers a lot of ground. In terms of technologies and techniques we have in the solution: Mach Mach Messages Mach Exceptions OS userspace and kernelspace copyin virtual memory exception handling Open Source XNU kernel Programming C and Assembly languages threads stacks race conditions and brute forcing error handling or its absence Now we just need to make sense of it all. The Road Ahead Having learnt where we can find Exploits, looking at our first exploit, and then seeing what technologies it relies upon, we can now chart out the road ahead. The Knowledge We Require No one book can cover all the required topics in depth. But with the appropriate hacker mindset, a small subset of a large number of technologies can be learnt within the confines of one book. After practice, a hacker mentality can zoom our attention to the most \"interesting\" aspects of a given technology. We should aim to have a T-shaped skill profile; shallow knowledge in many areas, but in-depth for certain pieces of those technologies. This is in contrast to a standard engineering T-shaped knowledge base where the in-depth knowledge is confined to one or two technologies. Engineering sensibilities If we are a professional software engineer, and look at Proof of Concept exploits the code structure and organisation often chafes at our engineering sensibilities. Compiler warning are ignored, variable names are terse or badly named. Functions are badly formed, with strange names, and dispersed business logic. Hardcoded values are rampant. But the programs do \"clever\" things and use techniques often advanced programmers are unaware of. This is really a reflection of the patchwork of in-depth skills a hacker will acquire. Brilliance in some aspects, and beginner in others. Of course, hackers can also be skilled software engineers, system administrators, or have another profession. Such skills can be complementary but are not foundational. Hacker skills are not built on top of a layer of great system administration skills, nor software engineering skills. The learning pathway There is a meta skill that underpins security research. That is, reading. We have a goal to reach but don't know half of the technologies needed. So we just do an internet search, pull down freely available learning material, and then skim through the contents. The canonical texts are usually the best. In the first iteration it is usually a matter of downloading a manual of hundreds of pages. Then pressing Page-Down repeatedly and skimming through. Maybe 10 seconds per page. We are building up a mental model from the lowest level detail in a particular topic. At that point we have awareness of what we don't know but enough knowledge to know a good search query to get into such a topic in more depth. Deconstructing our world Looking at canonical materials (that is, the text that most fully describes the content with a minimal amount of simplification) allows hackers to see systems as they really are, rather than an abstraction of what they are. Software engineering is really the construction of layers of abstraction to get to a point of understanding of the task most naturally in the problem space we are working with. Researchers need to think about computers in the way they actually work, with all the abstractions stripped bare. For example, when programmers see a virtual function in C++, they know that they need to look at what class is being messaged to understand what function the method will invoke. When hackers see a virtual function, they see that there must be a Virtual Function Table where the control flow is switched to the function that is desired. If the strategy in the mind of the researcher is to re-direct program control, then inspecting the code for virtual functions can be a goal. Furthermore, reading a C++ manual which tells about how late binding works (as explained above with Virtual Function tables) allows those with a hacker mentality to make a mental note of the implied trust relationship in that code at such points. The Virtual Function Table if subverted will change the operation of the program. Learning from Exploits Looking at existing exploits teaches what are the kinds of things about technologies we have that need to be learnt. That is so we don't waste effort on non-critical knowledge. Granted all knowledge is valuable, but time is always going to be finite. So a trade-off is needed between learning knowledge in case it might be useful versus learning only what is needed for the job in hand. The hacker mindset Our path in learning and discovery is aided by a hacker mindset. This is closely connected to human psychology. What do humans do, and what opportunities are indirectly afforded through such human nature? There are formal ways of thinking to encourage a hacker mindset. We shall explore this in later chapters. Research goals Looking at security exploits, we can ask what was the researcher aiming for which resulted in the fruits of the researcher. Research is not effective unless there is a strategic path that is being pursued. We shall explore this aspect of security research and show how this can amplify our efforts.","title":"The Hammer"},{"location":"Hammer/#the-hammer","text":"When studying past exploits it can feel like our brain has been hit by a hammer. It is because most exploit discussions work on the basis that we have had an apprenticeship on all the underlying techniques, and that only that final layer needs explanation. This approach is understandable from the writer's perspective. If we are a researcher we will naturally seek out underlying technologies, documentation and reading materials as part of our research journey. The writer's audience will be such researchers. So the writer will not dwell on the supporting techniques and technologies. Since iOS and macOS use many niche technologies, or use standard techniques with some Apple ecosystem unique twists, it is not so easy to do our background reading. In this chapter we shall look at an exploit write-up. Our purpose is not to understand the exploit as such, but to survey the techniques and technologies at play. It will provide us the motivation to explore such items in subsequent chapters knowing that this knowledge will then help us circle back and understand the originally presented exploit.","title":"The Hammer"},{"location":"Hammer/#getting-exploits","text":"Exploits can be downloaded from the Exploit Database Git Repository . This is a valuable resource and one we shall often refer to. The exploit database has a search tool, searchsploit . If we install searchsploit from Exploit Database Git Repository and configure our ~/.searchsploit_rc file then we can easily look up exploits. This is a search for items matching ios and dos : searchsploit ios dos | less ------------------------------- --------------------------------- Exploit Title | Path ------------------------------- --------------------------------- Apple iOS - Kernel Stack Memor | ios/dos/45649.txt Apple iOS 1.1.2 - Remote Denia | hardware/dos/4978.html Apple iOS 1.1.4/2.0 / iPod 1.1 | hardware/dos/32341.html Apple iOS 11.2.5 / watchOS 4.2 | multiple/dos/44215.m Apple iOS 4.0.3 - DPAP Server | ios/dos/5151.pl Apple iOS 5.1.1 Safari Browser | ios/dos/18931.rb Apple iOS < 10.3.2 - Notificat | ios/dos/42014.txt Apple iOS Kernel - Use-After-F | ios/dos/45652.c Apple iOS Mobile Safari - Memo | ios/dos/31057.html Apple iOS Safari - 'decodeURI' | hardware/dos/15794.php Apple iOS Safari - 'decodeURIC | hardware/dos/15796.php Apple iOS Safari - 'JS .' Remo | hardware/dos/15805.php Apple iOS Safari - Bad 'VML' R | ios/dos/11890.txt Apple iOS Safari - body alink | hardware/dos/15792.php Apple iOS Safari - Remote Deni | ios/dos/11891.txt Apple iOS/macOS - Kernel Memor | multiple/dos/45651.c Apple iOS/macOS - Sandbox Esca | multiple/dos/45648.txt Apple iOS/macOS - Sandbox Esca | multiple/dos/45650.txt Apple Mac OSX - IOSCSIPeripher | osx/dos/39376.c Exploits can be searched for, downloaded, and then explored. Each exploit has a number associated with it, known as the EDB-ID .","title":"Getting Exploits"},{"location":"Hammer/#copyin_leak-exploit-45649","text":"This program allows a user program to get the kernel to expose memory values it should not be able to see. In that sense it is an information disclosure \"leak\". The kernel routine used to do this is copyin hence it has been called a copyin_leak . The following command places a local copy of the exploit write-up in our local directory, known as the mirror (-m) command. # searchsploit -m 45649 Exploit: Apple iOS - Kernel Stack Memory Disclosure due to Failure to Check copyin Return Value URL: https://www.exploit-db.com/exploits/45649 Path: /Users/faisalm/dev/exploitdb/exploits/ios/dos/45649.txt File Type: ASCII text, with CRLF line terminators Copied to: /Users/faisalm/dev/scratch/45649.txt From looking at the text file, we find we can download the actual Proof of Concept (POC) from a Git Hub web address. This provides us an app to run on simulator or on an iDevice. This POC has been tested on iPod touch (7th generation) iOS 13.5 (17F75) and iPod touch (7th generation) simulator iOS 14.4 (18D46)","title":"copyin_leak Exploit 45649"},{"location":"Hammer/#copyin_leak-write-up","text":"Here is the verbatim text for the write-up of this leak. The purpose for including it is to show the \"level\" at which exploit research is aimed at. The main aim of this book is to bring ourselves up to the same level so we can appreciate this piece of research, and then move forwards onto exploring and finding our own vulnerabilities. Here's a code snippet from sleh.c with the second level exception handler for undefined instruction exceptions: static void handle_uncategorized ( arm_saved_state_t * state , boolean_t instrLen2 ) { exception_type_t exception = EXC_BAD_INSTRUCTION ; mach_exception_data_type_t codes [ 2 ] = { EXC_ARM_UNDEFINED }; mach_msg_type_number_t numcodes = 2 ; uint32_t instr ; // <------- (a) if ( instrLen2 ) { uint16_t instr16 ; COPYIN ( get_saved_state_pc ( state ), ( char * ) & instr16 , sizeof ( instr16 )); instr = instr16 ; } else { COPYIN ( get_saved_state_pc ( state ), ( char * ) & instr , sizeof ( instr )); <------- ( b ) } .... else { codes [ 1 ] = instr ; <------ ( c ) } } exception_triage ( exception , codes , numcodes ); <-------- ( d ) At (a) the uint32_t instr is declared uninitialized on the stack. At (b) the code tries to copyin the bytes of the exception-causing instruction from userspace note that the COPYIN macro doesn't itself check the return value of copyin, it just calls it. At (c) instr is assigned to codes[1] , which at (d) is passed to exception_triage . That codes array will eventually end up being sent in an exception mach message. The bug is that we can force copyin to fail by unmapping the page containing the undefined instruction while it's being handled. (I tried to do this with XO memory but the kernel seems to be able to copyin that just fine.) This PoC has an undefined instruction (0xdeadbeef) on its own page and spins up a thread to keep switching the protection of that page between VM_PROT_NONE and VM_PROT_READ|VM_PROT_EXECUTE . We then keep spinning up threads which try to execute that undefined instruction. If the race windows align the thread executes the undefined instruction but when the sleh code tries to copyin the page is unmapped, the copying fails and the exception message we get has stale stack memory. This PoC just demonstrates that we do get values which aren't 0xdeadbeef in there for the EXC_ARM_UNDEFINED type. We'd have to do a bit more fiddling to work out how to get something specific there. Note that there are lots of other unchecked COPYIN 's in sleh.c (eg when userspace tries to access a system register not allowed for EL0) and these seem to have the same issue. tested on iPod Touch 6g running 11.3.1, but looking at the kernelcache it seems to still be there in iOS 12. Proof of Concept: https://github.com/offensive-security/exploitdb-bin-sploits/raw/m aster/bin-sploits/45649.zip That's the end of the write-up. It covers a lot of ground. In terms of technologies and techniques we have in the solution: Mach Mach Messages Mach Exceptions OS userspace and kernelspace copyin virtual memory exception handling Open Source XNU kernel Programming C and Assembly languages threads stacks race conditions and brute forcing error handling or its absence Now we just need to make sense of it all.","title":"copyin_leak write-up"},{"location":"Hammer/#the-road-ahead","text":"Having learnt where we can find Exploits, looking at our first exploit, and then seeing what technologies it relies upon, we can now chart out the road ahead.","title":"The Road Ahead"},{"location":"Hammer/#the-knowledge-we-require","text":"No one book can cover all the required topics in depth. But with the appropriate hacker mindset, a small subset of a large number of technologies can be learnt within the confines of one book. After practice, a hacker mentality can zoom our attention to the most \"interesting\" aspects of a given technology. We should aim to have a T-shaped skill profile; shallow knowledge in many areas, but in-depth for certain pieces of those technologies. This is in contrast to a standard engineering T-shaped knowledge base where the in-depth knowledge is confined to one or two technologies.","title":"The Knowledge We Require"},{"location":"Hammer/#engineering-sensibilities","text":"If we are a professional software engineer, and look at Proof of Concept exploits the code structure and organisation often chafes at our engineering sensibilities. Compiler warning are ignored, variable names are terse or badly named. Functions are badly formed, with strange names, and dispersed business logic. Hardcoded values are rampant. But the programs do \"clever\" things and use techniques often advanced programmers are unaware of. This is really a reflection of the patchwork of in-depth skills a hacker will acquire. Brilliance in some aspects, and beginner in others. Of course, hackers can also be skilled software engineers, system administrators, or have another profession. Such skills can be complementary but are not foundational. Hacker skills are not built on top of a layer of great system administration skills, nor software engineering skills.","title":"Engineering sensibilities"},{"location":"Hammer/#the-learning-pathway","text":"There is a meta skill that underpins security research. That is, reading. We have a goal to reach but don't know half of the technologies needed. So we just do an internet search, pull down freely available learning material, and then skim through the contents. The canonical texts are usually the best. In the first iteration it is usually a matter of downloading a manual of hundreds of pages. Then pressing Page-Down repeatedly and skimming through. Maybe 10 seconds per page. We are building up a mental model from the lowest level detail in a particular topic. At that point we have awareness of what we don't know but enough knowledge to know a good search query to get into such a topic in more depth.","title":"The learning pathway"},{"location":"Hammer/#deconstructing-our-world","text":"Looking at canonical materials (that is, the text that most fully describes the content with a minimal amount of simplification) allows hackers to see systems as they really are, rather than an abstraction of what they are. Software engineering is really the construction of layers of abstraction to get to a point of understanding of the task most naturally in the problem space we are working with. Researchers need to think about computers in the way they actually work, with all the abstractions stripped bare. For example, when programmers see a virtual function in C++, they know that they need to look at what class is being messaged to understand what function the method will invoke. When hackers see a virtual function, they see that there must be a Virtual Function Table where the control flow is switched to the function that is desired. If the strategy in the mind of the researcher is to re-direct program control, then inspecting the code for virtual functions can be a goal. Furthermore, reading a C++ manual which tells about how late binding works (as explained above with Virtual Function tables) allows those with a hacker mentality to make a mental note of the implied trust relationship in that code at such points. The Virtual Function Table if subverted will change the operation of the program.","title":"Deconstructing our world"},{"location":"Hammer/#learning-from-exploits","text":"Looking at existing exploits teaches what are the kinds of things about technologies we have that need to be learnt. That is so we don't waste effort on non-critical knowledge. Granted all knowledge is valuable, but time is always going to be finite. So a trade-off is needed between learning knowledge in case it might be useful versus learning only what is needed for the job in hand.","title":"Learning from Exploits"},{"location":"Hammer/#the-hacker-mindset","text":"Our path in learning and discovery is aided by a hacker mindset. This is closely connected to human psychology. What do humans do, and what opportunities are indirectly afforded through such human nature? There are formal ways of thinking to encourage a hacker mindset. We shall explore this in later chapters.","title":"The hacker mindset"},{"location":"Hammer/#research-goals","text":"Looking at security exploits, we can ask what was the researcher aiming for which resulted in the fruits of the researcher. Research is not effective unless there is a strategic path that is being pursued. We shall explore this aspect of security research and show how this can amplify our efforts.","title":"Research goals"},{"location":"Introduction/","text":"Introduction This web-based book is about Zero Day Vulnerabilities. It is called \"The Road to Zero\" because it is primarily a tutorial guide to take you along the path needed to find your own vulnerabilities. The focus of our book is iOS. In fact, when we talk about iOS we often mean the family of Operating Systems from Apple that are based around the same underpinnings. It would be more accurate to say this book focusses on Darwin, the common UNIX and NeXT technology stack from which macOS, iOS, tvOS, and watchOS are derived. Likewise when we refer to a device, we say iDevice because there are lots of different Apple produced products in different device classes, such as various models of iPhone, iPod or iPad. There will be a companion Udemy course to accompany the book. Hopefully this will accomodate different learning styles. The book is better for drilling into subtle details, but the videos are better to getting a sense of the interactive and exploratory aspects of vulnerability hunting. The book will remain cost free, and the Udemy course will be at a reasonable cost.","title":"Introduction"},{"location":"Introduction/#introduction","text":"This web-based book is about Zero Day Vulnerabilities. It is called \"The Road to Zero\" because it is primarily a tutorial guide to take you along the path needed to find your own vulnerabilities. The focus of our book is iOS. In fact, when we talk about iOS we often mean the family of Operating Systems from Apple that are based around the same underpinnings. It would be more accurate to say this book focusses on Darwin, the common UNIX and NeXT technology stack from which macOS, iOS, tvOS, and watchOS are derived. Likewise when we refer to a device, we say iDevice because there are lots of different Apple produced products in different device classes, such as various models of iPhone, iPod or iPad. There will be a companion Udemy course to accompany the book. Hopefully this will accomodate different learning styles. The book is better for drilling into subtle details, but the videos are better to getting a sense of the interactive and exploratory aspects of vulnerability hunting. The book will remain cost free, and the Udemy course will be at a reasonable cost.","title":"Introduction"},{"location":"JailbreakSetup/","text":"Jailbreak Setup In order to explore the iOS attack surface directly we need to explore the iOS system using diagnostic tools. Such tooling is not available under normal circumstances. Apple engineering will be able to diagnose and explore iOS using specially constructed iPhones, so-called \"Dev Fused\" hardware. This provides full access to the iPhone. External engineers on the Security Research Device programme (see @applesrd) will be able to access a similiar phone, called a \"SRD Fused\" hardware. This provides ssh access to the iPhone. Such engineers can choose any entitlements and therefore can run any software on the phone. Approved organisations can get access to a virtualization as a service platform from Corellium which provides a diagnostic experience from kernel level to any iOS OS image that we upload to test. (See @corelliumvirtualdevices) Ordinary customers use production iPhones, \"Prod Fused\" hardware. These have the full set of security restrictions of an iPhone. (See @srdhowworks) The workaround that most zero day researchers use is to take Prod Fused hardware, and keep the software an an old iOS revision, potentially also staying on old hardware. Over time, software might be released to circumvent the security restrictions of our iDevice. Staying on old hardware increases the likelyhood of such software become available since the latest hardware protections schemes might not have a public exploit. Using software to exploit vulnerabilities to permit elevated access to the iDevice is called Jailbreaking. Because the software and hardware restrictions keep our software \"Jailed\" by denying freedom to access system resources. Jailbreaks break us out from such a Jail. Types of Jailbreak There are different levels by which access restrictions can be disabled on an iDevice. The key differentiator is what happens to the device when it is booting up, such as during power on or a restart, and whether manual steps are needed following boot up. In this section, tethering means physically connecting the iDevice to a computer with a cable (the tether) and running special software on the computer. Tethering is significant because in practice mobile devices are no longer very \"mobile\" when they need to be hooked up to a computer albeit a laptop. The different types of jailbreak are: Tethered; must boot using a computer, without a computer it will not boot Semi-tethered; may boot using a computer (to get jailbreak functionality), or boot without a computer (to get normal functionality) Untethered; can boot without a computer and will get jailbreak functionality Semi-untethered; can boot without a computer to get normal functionality, run an on-device app to apply the jailbreak This can be summarized in the following table. Type Tethered reboot Untethered reboot After JB app Tethered Jailbroken Hangs or Crashes N/A Semi-tethered Jailbroken Normal Functionality N/A Untethered N/A Jailbroken N/A Semi-untethered N/A Normal Functionality Jailbroken For our purposes, any of the above approaches are acceptable because we shall be mostly working on our laytop/desktop computer and remotely connecting to our iDevice, which will typically be physically connected as well. In practice, the most common form of jailbreak is the Semi-untethered jailbreak. Jailbreak shopping list There are many jailbreak software programs, many hardware variants. The steps to follow also vary with the jailbreak itself. Rather than track these rapidly evolving factors, some broad guidance is given here. We take note of the local laws. It seems that in USA, and most countries, jailbreaking for (@jailbreakingallowed) We need a Mac running macOS. Other options are possible but there is a smaller user base for alternative configurations, so the out-of-the-box experience might not be as smooth. Beware of scams, as Jailbreak tools should be free in cost. The best anchor point to reach download sites is to start from https://www.theiphonewiki.com This is the primary resource site which encapsulates the latest knowledge of tools, phones, and techniques. We need a paid Apple developer account. This allows us to re-sign the app install files, known as .IPA files. We need to enable an application specific password for our Paid Developer account. (See @appspecificpassword) We need and old iDevice. Perhaps a second hand one, or one that we had used in the past before upgrading, or a cosemetically damaged phone. A good choice is an iPod Touch, 7th generation. This is not too old, quite cheap, but has many options for jailbreaking. Such devices will likely have a long life because they are often embedded to other hardware such as point of sale terminals. Example Jailbreak steps Whilst the specific details will depend on our software and hardware versions, a typical jailbreak involves steps similar to the following: Confirm our Mac is running with Xcode, and can deploy a trivial app to our phone. Update the Apple ID to have a application specific password. Download the Unc0ver jailbreak. Download the Cydia Impactor Tool and install it. Drag the Unc0ver IPA file onto Cydia Impactor. Supply the Apple ID, and the application specific password. Follow the On-Device prompts in the Unc0ver app, and then let it reboot. Enable ssh on the iDevice and change the root/alpine credentials to something unique.","title":"Jailbreak Setup"},{"location":"JailbreakSetup/#jailbreak-setup","text":"In order to explore the iOS attack surface directly we need to explore the iOS system using diagnostic tools. Such tooling is not available under normal circumstances. Apple engineering will be able to diagnose and explore iOS using specially constructed iPhones, so-called \"Dev Fused\" hardware. This provides full access to the iPhone. External engineers on the Security Research Device programme (see @applesrd) will be able to access a similiar phone, called a \"SRD Fused\" hardware. This provides ssh access to the iPhone. Such engineers can choose any entitlements and therefore can run any software on the phone. Approved organisations can get access to a virtualization as a service platform from Corellium which provides a diagnostic experience from kernel level to any iOS OS image that we upload to test. (See @corelliumvirtualdevices) Ordinary customers use production iPhones, \"Prod Fused\" hardware. These have the full set of security restrictions of an iPhone. (See @srdhowworks) The workaround that most zero day researchers use is to take Prod Fused hardware, and keep the software an an old iOS revision, potentially also staying on old hardware. Over time, software might be released to circumvent the security restrictions of our iDevice. Staying on old hardware increases the likelyhood of such software become available since the latest hardware protections schemes might not have a public exploit. Using software to exploit vulnerabilities to permit elevated access to the iDevice is called Jailbreaking. Because the software and hardware restrictions keep our software \"Jailed\" by denying freedom to access system resources. Jailbreaks break us out from such a Jail.","title":"Jailbreak Setup"},{"location":"JailbreakSetup/#types-of-jailbreak","text":"There are different levels by which access restrictions can be disabled on an iDevice. The key differentiator is what happens to the device when it is booting up, such as during power on or a restart, and whether manual steps are needed following boot up. In this section, tethering means physically connecting the iDevice to a computer with a cable (the tether) and running special software on the computer. Tethering is significant because in practice mobile devices are no longer very \"mobile\" when they need to be hooked up to a computer albeit a laptop. The different types of jailbreak are: Tethered; must boot using a computer, without a computer it will not boot Semi-tethered; may boot using a computer (to get jailbreak functionality), or boot without a computer (to get normal functionality) Untethered; can boot without a computer and will get jailbreak functionality Semi-untethered; can boot without a computer to get normal functionality, run an on-device app to apply the jailbreak This can be summarized in the following table. Type Tethered reboot Untethered reboot After JB app Tethered Jailbroken Hangs or Crashes N/A Semi-tethered Jailbroken Normal Functionality N/A Untethered N/A Jailbroken N/A Semi-untethered N/A Normal Functionality Jailbroken For our purposes, any of the above approaches are acceptable because we shall be mostly working on our laytop/desktop computer and remotely connecting to our iDevice, which will typically be physically connected as well. In practice, the most common form of jailbreak is the Semi-untethered jailbreak.","title":"Types of Jailbreak"},{"location":"JailbreakSetup/#jailbreak-shopping-list","text":"There are many jailbreak software programs, many hardware variants. The steps to follow also vary with the jailbreak itself. Rather than track these rapidly evolving factors, some broad guidance is given here. We take note of the local laws. It seems that in USA, and most countries, jailbreaking for (@jailbreakingallowed) We need a Mac running macOS. Other options are possible but there is a smaller user base for alternative configurations, so the out-of-the-box experience might not be as smooth. Beware of scams, as Jailbreak tools should be free in cost. The best anchor point to reach download sites is to start from https://www.theiphonewiki.com This is the primary resource site which encapsulates the latest knowledge of tools, phones, and techniques. We need a paid Apple developer account. This allows us to re-sign the app install files, known as .IPA files. We need to enable an application specific password for our Paid Developer account. (See @appspecificpassword) We need and old iDevice. Perhaps a second hand one, or one that we had used in the past before upgrading, or a cosemetically damaged phone. A good choice is an iPod Touch, 7th generation. This is not too old, quite cheap, but has many options for jailbreaking. Such devices will likely have a long life because they are often embedded to other hardware such as point of sale terminals.","title":"Jailbreak shopping list"},{"location":"JailbreakSetup/#example-jailbreak-steps","text":"Whilst the specific details will depend on our software and hardware versions, a typical jailbreak involves steps similar to the following: Confirm our Mac is running with Xcode, and can deploy a trivial app to our phone. Update the Apple ID to have a application specific password. Download the Unc0ver jailbreak. Download the Cydia Impactor Tool and install it. Drag the Unc0ver IPA file onto Cydia Impactor. Supply the Apple ID, and the application specific password. Follow the On-Device prompts in the Unc0ver app, and then let it reboot. Enable ssh on the iDevice and change the root/alpine credentials to something unique.","title":"Example Jailbreak steps"},{"location":"KernelDebugging/","text":"Kernel Debugging There is a good textbook on the Darwin family of Operating Systems; see @newosxbook. In this chapter however, we aim for a practical hands-on approach, and defer theory until later on our journey. Discovering 0-days is mostly a practical exercise, accompanied by a knowledge of strategy, a bedrock of theory, and a toolchain of reverse engineering tools. In the same way that beginner programmers, particularly from an academic training, try to design and architect their system before starting to code (and thus missing information and hitting knowledge gaps), beginner hackers try to read everything about the target system before cracking them. Hacking is mostly a journey of discovery just like software engineering. Only trivial, or previously well practiced systems are ameniable to big up-front design approaches. Also, knowing less about a system can sometimes be advantageous because new avenues are tried or novel approaches are discovered.","title":"Kernel Debugging"},{"location":"KernelDebugging/#kernel-debugging","text":"There is a good textbook on the Darwin family of Operating Systems; see @newosxbook. In this chapter however, we aim for a practical hands-on approach, and defer theory until later on our journey. Discovering 0-days is mostly a practical exercise, accompanied by a knowledge of strategy, a bedrock of theory, and a toolchain of reverse engineering tools. In the same way that beginner programmers, particularly from an academic training, try to design and architect their system before starting to code (and thus missing information and hitting knowledge gaps), beginner hackers try to read everything about the target system before cracking them. Hacking is mostly a journey of discovery just like software engineering. Only trivial, or previously well practiced systems are ameniable to big up-front design approaches. Also, knowing less about a system can sometimes be advantageous because new avenues are tried or novel approaches are discovered.","title":"Kernel Debugging"},{"location":"Mach/","text":"Mach Programming Motivation The Operating Systems we know as iOS, macOS, tvOS, etc. are really different flavors of the Darwin Operating System. The same code base but compiled with different macro preprocessor flags. The kernel of Darwin is XNU. The fundamental interface to XNU is via the Mach programming interface. At its core, XNU is based upon Mach messages. The reason why we want to do Mach programming is because it is an interface available from user mode that can affect, leak or subvert the XNU kernel since they share the same data abstractions and programming methodology. Furthermore the fundamental abstractions are available as Open Source so can be inspected and understood easily. One way to think about Mach is to consider it a fundamental building block that can be used to build out an Operating System personality. Apple have created a UNIX personality for Darwin using Mach as an enabling technology. That is why there seems to be two competing interfaces in Darwin, the Mach programming interface, and the UNIX syscall interface. It is straightforward to learn the UNIX syscall interface, because it follows the same paradigm as Linux. There are therefore many books and example programs written against the UNIX syscall interface. The details will vary but the approach is the same. The Mach programming interface is somewhat esoteric. Apple seem to like to pretend that it does not exist. Even experienced iOS programmers will know little to nothing about it. However, time and again, this interface will be used to build exploits, so it is something we shall learn. The original idea with Mach was to extend UNIX with new capabilities to tackle the emergence of multiprocessor systems and distributed computing more naturally. The solution was to add a new set of messaging primitives; see A Programmer's Guide to the Mach System Calls When correctly coded, Mach based solutions can be elegant. When incorrectly coded, Mach based code offers an expansive attack surface. We shall study different techniques that abuse the Mach messaging system, such as Type Confusion. Furthermore, Mach based attacks can be Data oriented attacks, which side-step the traditional mitigations in the Operating System (such as stack overflow protection and control flow integrity). Mach Fundamental Abstractions Mach is built upon the following abstractions: Entry Meaning task An execution environment. thread The basic unit of execution. port A communication channel. message A typed collection of data used for communication between threads. In the original formulation, tasks could be on the same machine, on different processors in the machine, or on different machines. Such tasks become active entities when they host one or more threads. And threads can communicate with each other using well-defined interfaces that are invariant to whether the recipient is on the same machine or on a different machine. In reality, due to the irrepressible properties of distributed communication, latency and reliability cannot be ignored. Therefore, such a uniform communication abstraction cannot work out satisfactorily in real systems. However, within a CPU with threads from the same task, or tasks in a parent-child relationship, the inherently well designed message passing abstraction comes into its own. This is where the XNU kernel does its work and shines. How to learn Mach programming Mach is not so easy to learn. There are few modern programs on GitHub to look at. One way into the topic is to study the NEXTSTEP Mach documentation. Despite its age, it is a well structured explanation of the concepts. Another source of documentation are the header files on macOS. We can find the header file directory with: # find /Applications/Xcode.app -type d -iname mach /Applications/Xcode.app/Contents/Developer/Platforms/AppleTVOS.pl atform/Developer/SDKs/AppleTVOS.sdk/usr/include/mach /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.pla tform/Developer/SDKs/iPhoneOS.sdk/usr/include/mach . . . Rather than duplicate or replace the NEXTSTEP documentation, we assume the reader will read all of that documentation, but for the practical work elements, refer to this book. This book then acts as a modernization of the original materials. As mentioned in the Introduction, this book is largely a tutorial guide to get us along the path to being able to find 0-day vulnerabilities. Memory Allocation Here we follow along the Mach documentation but with modernized code examples. These are available at The Road to Zero GitHub in the subdirectory source/mach-vm-alloc Here is code that demonstrates how to allocate memory with Mach, how to duplicate memory, and then how to free memory. int vm_example () { union data_area { char * indexed ; vm_address_t handle ; } data1 , data2 ; vm_size_t i ; vm_size_t min ; mach_msg_type_number_t data_cnt ; mach_port_t self ; char * error = NULL ; kern_return_t rv = KERN_SUCCESS ; printf ( \" \\n START: vm_example() \\n \" ); self = mach_task_self (); printf ( \"mach_task_self is 0x%x \\n \" , self ); rv = vm_allocate ( self , & data1 . handle , vm_page_size , TRUE ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_allocate\" ; goto vm_example_error_return ; } for ( i = 0 ; ( i < vm_page_size ); i ++ ) { data1 . indexed [ i ] = i ; } printf ( \"Filled space allocated with some data. \\n \" ); printf ( \"Doing vm_read.... \\n \" ); rv = vm_read ( self , data1 . handle , vm_page_size , & data2 . handle , & data_cnt ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_read\" ; goto vm_example_error_return ; } printf ( \"Successful vm_read. \\n \" ); if ( vm_page_size != data_cnt ) { error = \"vmread: Number of bytes read not equal to number available and requested . \"; goto vm_example_logic_error_return ; } min = ( vm_page_size < data_cnt ) ? vm_page_size : data_cnt ; for ( i = 0 ; ( i < min ); i ++ ) { if ( data1 . indexed [ i ] != data2 . indexed [ i ]) { error = \"Data not read correctly\" ; goto vm_example_logic_error_return ; } } printf ( \"Checked data successfully. \\n \" ); rv = vm_deallocate ( self , data1 . handle , vm_page_size ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_deallocate\" ; goto vm_example_error_return ; } rv = vm_deallocate ( self , data2 . handle , data_cnt ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_deallocate\" ; goto vm_example_error_return ; } printf ( \"END: vm_example() \\n \" ); return 0 ; vm_example_error_return : printf ( \"%s: %s \\n \" , error , mach_error_string ( rv )); return -1 ; vm_example_logic_error_return : printf ( \"%s \\n \" , error ); return -1 ; } Memory Allocation discussion In our code example, there are two stylistic points to note: We use a union to clearly characterise that Mach calls accept a handle, which is a vm_address_t but is clearly also just a raw pointer, char * , so we create a union comprising these two types depending on whether we are issuing Mach calls or doing normal C-based pointer arithmetic. The union avoids us having to use type casts. We use a goto idiom to handle errors. All our goto statements go forwards (so don't generate loops in our code) and just handle the error cases. This makes such exception handling clean without too much code repetition. That is useful because nearly all our function calls can return an error to be checked. In our code we make the following observations: We need to have the port of the task before any of the system calls can be made because any message port the system returns is namespaced to port of the task it relates to. mach_task_self() provides us this. It is not actually a function call, it is a #define which provides us our thread-specific task value. The value is typically a small integer. vm_allocate() allocates memory. It is logical to ask for a page sized amount of memory because this is the unit of memory upon which virtual protection and management is done. This will be 16 KiB. vm_read() actually also allocates memory as vm_allocate() does. The function names do not have a nomenclature that tells us this, so it is worthwhile checking the function meaning each time until we are familiar with them. vm_deallocate() deallocates our memory; we did a vm_allocate() and a vm_read() allocation so there are two pages of memory to free up. It is a good practice to check return values against != KERN_SUCCESS and let mach_error_string handle the different possible error return values, since there are many error values possible. This vm_example() code merely needs to be hooked into our App code when it launches, in the main() function to operate. It does feel heavyweight for what it does. Copy-on-Write Memory The following example shows how Mach will Copy-on-Write pages of memory which are shared. enum copy_on_write_constants { COPY_ON_WRITE = 0 , PARENT_CHANGED = 1 , CHILD_CHANGED = 2 , }; enum lock_constants { NO_ONE_WAIT = 0 , PARENT_WAIT = 1 , CHILD_WAIT = 2 }; char * lock_status [] = { \"NO_ONE_WAIT 0\" , \"PARENT_WAIT 1\" , \"CHILD_WAIT 2\" }; char * cow_status [] = { \"COPY_ON_WRITE 0\" , \"PARENT_CHANGED 1\" , \"CHILD_CHANGED 2\" }; int vm_copy_on_write_example () { union data_area { char * indexed ; vm_address_t handle ; } lock , mem ; mach_port_t self ; char * error = NULL ; kern_return_t rv = KERN_SUCCESS ; pid_t pid ; const int MAXDATA = 100 ; printf ( \" \\n START: vm_copy_on_write_example() \\n \" ); self = mach_task_self (); rv = vm_allocate ( self , & lock . handle , sizeof ( int ), TRUE ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_allocate\" ; goto vm_cow_error_return ; } rv = vm_inherit ( self , lock . handle , sizeof ( int ), VM_INHERIT_SHARE ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_inherit\" ; goto vm_cow_error_return ; } * lock . indexed = NO_ONE_WAIT ; rv = vm_allocate ( self , & mem . handle , sizeof ( int ) * MAXDATA , TRUE ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_allocate\" ; goto vm_cow_error_return ; } mem . indexed [ 0 ] = COPY_ON_WRITE ; printf ( \"value of lock before fork: %s \\n \" , lock_status [ * lock . indexed ]); pid = fork (); if ( pid ) { printf ( \"PARENT: copied memory = %s \\n \" , cow_status [ mem . indexed [ 0 ]]); printf ( \"PARENT: changing to %s \\n \" , cow_status [ PARENT_CHANGED ]); mem . indexed [ 0 ] = PARENT_CHANGED ; printf ( \" \\n \" ); printf ( \"PARENT: lock = %s \\n \" , lock_status [ * lock . indexed ]); printf ( \"PARENT: changing lock to %s \\n \" , lock_status [ PARENT_WAIT ]); printf ( \" \\n \" ); * lock . indexed = PARENT_WAIT ; while ( * lock . indexed == PARENT_WAIT ) { /* wait for child to change the value */ ; } printf ( \"PARENT: copied memory = %s \\n \" , cow_status [ mem . indexed [ 0 ]]); printf ( \"PARENT: lock = %s \\n \" , lock_status [ * lock . indexed ]); printf ( \"PARENT: Finished. \\n \" ); * lock . indexed = PARENT_WAIT ; exit ( -1 ); } while ( * lock . indexed != PARENT_WAIT ) { /* wait for parent to change lock */ ; } printf ( \"CHILD: copied memory = %s \\n \" , cow_status [ mem . indexed [ 0 ]]); printf ( \"CHILD: changing to %s \\n \" , cow_status [ CHILD_CHANGED ]); mem . indexed [ 0 ] = CHILD_CHANGED ; printf ( \" \\n \" ); printf ( \"CHILD: lock = %s \\n \" , lock_status [ * lock . indexed ]); printf ( \"CHILD: changing lock to %s \\n \" , lock_status [ CHILD_WAIT ]); printf ( \" \\n \" ); * lock . indexed = CHILD_WAIT ; while ( * lock . indexed == CHILD_WAIT ) { /* wait for parent to change lock */ ; } rv = vm_deallocate ( mach_task_self (), lock . handle , sizeof ( int )); if ( rv != KERN_SUCCESS ) { error = \"vm_deallocate failed\" ; goto vm_cow_error_return ; } rv = vm_deallocate ( mach_task_self (), mem . handle , sizeof ( int ) * MAXDATA ); if ( rv != KERN_SUCCESS ) { error = \"vm_deallocate failed\" ; goto vm_cow_error_return ; } printf ( \"CHILD: Finished. \\n \" ); printf ( \"END: vm_copy_on_write_example() \\n \" ); return 0 ; vm_cow_error_return : printf ( \"%s: %s \\n \" , error , mach_error_string ( rv )); return -1 ; } This program produces the following output: START: vm_copy_on_write_example() value of lock before fork: NO_ONE_WAIT 0 PARENT: copied memory = COPY_ON_WRITE 0 PARENT: changing to PARENT_CHANGED 1 PARENT: lock = NO_ONE_WAIT 0 PARENT: changing lock to PARENT_WAIT 1 CHILD: copied memory = COPY_ON_WRITE 0 CHILD: changing to CHILD_CHANGED 2 CHILD: lock = PARENT_WAIT 1 CHILD: changing lock to CHILD_WAIT 2 PARENT: copied memory = PARENT_CHANGED 1 PARENT: lock = CHILD_WAIT 2 PARENT: Finished. CHILD: Finished. END: vm_copy_on_write_example() Copy-on-Write Discussion As we can see the vm_inherit() routine will provide both the child and parent access to the same memory until it is modified. After that, the child and parent have separate memory pages representing their own copy of the data values which can now be different. This program uses a very primitive form of task coordination: busy while loops. A realistic example would use the pthread library instead for signalling and coordination. Further steps We now leave the Mach programming introduction. There aren't really any big example programs that use Mach so it is hard to get an appreciation of how to program with it. The main Mach program is the XNU kernel itself. So our next steps on our learning journey is to understand how to debug and probe the XNU kernel. From this we can get live experience with how Mach works. We shall see how the system interacts with Mach and how security (Mandatory Access Control (MAC)) is woven into the system at this lowest level.","title":"Mach Programming"},{"location":"Mach/#mach-programming","text":"","title":"Mach Programming"},{"location":"Mach/#motivation","text":"The Operating Systems we know as iOS, macOS, tvOS, etc. are really different flavors of the Darwin Operating System. The same code base but compiled with different macro preprocessor flags. The kernel of Darwin is XNU. The fundamental interface to XNU is via the Mach programming interface. At its core, XNU is based upon Mach messages. The reason why we want to do Mach programming is because it is an interface available from user mode that can affect, leak or subvert the XNU kernel since they share the same data abstractions and programming methodology. Furthermore the fundamental abstractions are available as Open Source so can be inspected and understood easily. One way to think about Mach is to consider it a fundamental building block that can be used to build out an Operating System personality. Apple have created a UNIX personality for Darwin using Mach as an enabling technology. That is why there seems to be two competing interfaces in Darwin, the Mach programming interface, and the UNIX syscall interface. It is straightforward to learn the UNIX syscall interface, because it follows the same paradigm as Linux. There are therefore many books and example programs written against the UNIX syscall interface. The details will vary but the approach is the same. The Mach programming interface is somewhat esoteric. Apple seem to like to pretend that it does not exist. Even experienced iOS programmers will know little to nothing about it. However, time and again, this interface will be used to build exploits, so it is something we shall learn. The original idea with Mach was to extend UNIX with new capabilities to tackle the emergence of multiprocessor systems and distributed computing more naturally. The solution was to add a new set of messaging primitives; see A Programmer's Guide to the Mach System Calls When correctly coded, Mach based solutions can be elegant. When incorrectly coded, Mach based code offers an expansive attack surface. We shall study different techniques that abuse the Mach messaging system, such as Type Confusion. Furthermore, Mach based attacks can be Data oriented attacks, which side-step the traditional mitigations in the Operating System (such as stack overflow protection and control flow integrity).","title":"Motivation"},{"location":"Mach/#mach-fundamental-abstractions","text":"Mach is built upon the following abstractions: Entry Meaning task An execution environment. thread The basic unit of execution. port A communication channel. message A typed collection of data used for communication between threads. In the original formulation, tasks could be on the same machine, on different processors in the machine, or on different machines. Such tasks become active entities when they host one or more threads. And threads can communicate with each other using well-defined interfaces that are invariant to whether the recipient is on the same machine or on a different machine. In reality, due to the irrepressible properties of distributed communication, latency and reliability cannot be ignored. Therefore, such a uniform communication abstraction cannot work out satisfactorily in real systems. However, within a CPU with threads from the same task, or tasks in a parent-child relationship, the inherently well designed message passing abstraction comes into its own. This is where the XNU kernel does its work and shines.","title":"Mach Fundamental Abstractions"},{"location":"Mach/#how-to-learn-mach-programming","text":"Mach is not so easy to learn. There are few modern programs on GitHub to look at. One way into the topic is to study the NEXTSTEP Mach documentation. Despite its age, it is a well structured explanation of the concepts. Another source of documentation are the header files on macOS. We can find the header file directory with: # find /Applications/Xcode.app -type d -iname mach /Applications/Xcode.app/Contents/Developer/Platforms/AppleTVOS.pl atform/Developer/SDKs/AppleTVOS.sdk/usr/include/mach /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.pla tform/Developer/SDKs/iPhoneOS.sdk/usr/include/mach . . . Rather than duplicate or replace the NEXTSTEP documentation, we assume the reader will read all of that documentation, but for the practical work elements, refer to this book. This book then acts as a modernization of the original materials. As mentioned in the Introduction, this book is largely a tutorial guide to get us along the path to being able to find 0-day vulnerabilities.","title":"How to learn Mach programming"},{"location":"Mach/#memory-allocation","text":"Here we follow along the Mach documentation but with modernized code examples. These are available at The Road to Zero GitHub in the subdirectory source/mach-vm-alloc Here is code that demonstrates how to allocate memory with Mach, how to duplicate memory, and then how to free memory. int vm_example () { union data_area { char * indexed ; vm_address_t handle ; } data1 , data2 ; vm_size_t i ; vm_size_t min ; mach_msg_type_number_t data_cnt ; mach_port_t self ; char * error = NULL ; kern_return_t rv = KERN_SUCCESS ; printf ( \" \\n START: vm_example() \\n \" ); self = mach_task_self (); printf ( \"mach_task_self is 0x%x \\n \" , self ); rv = vm_allocate ( self , & data1 . handle , vm_page_size , TRUE ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_allocate\" ; goto vm_example_error_return ; } for ( i = 0 ; ( i < vm_page_size ); i ++ ) { data1 . indexed [ i ] = i ; } printf ( \"Filled space allocated with some data. \\n \" ); printf ( \"Doing vm_read.... \\n \" ); rv = vm_read ( self , data1 . handle , vm_page_size , & data2 . handle , & data_cnt ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_read\" ; goto vm_example_error_return ; } printf ( \"Successful vm_read. \\n \" ); if ( vm_page_size != data_cnt ) { error = \"vmread: Number of bytes read not equal to number available and requested . \"; goto vm_example_logic_error_return ; } min = ( vm_page_size < data_cnt ) ? vm_page_size : data_cnt ; for ( i = 0 ; ( i < min ); i ++ ) { if ( data1 . indexed [ i ] != data2 . indexed [ i ]) { error = \"Data not read correctly\" ; goto vm_example_logic_error_return ; } } printf ( \"Checked data successfully. \\n \" ); rv = vm_deallocate ( self , data1 . handle , vm_page_size ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_deallocate\" ; goto vm_example_error_return ; } rv = vm_deallocate ( self , data2 . handle , data_cnt ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_deallocate\" ; goto vm_example_error_return ; } printf ( \"END: vm_example() \\n \" ); return 0 ; vm_example_error_return : printf ( \"%s: %s \\n \" , error , mach_error_string ( rv )); return -1 ; vm_example_logic_error_return : printf ( \"%s \\n \" , error ); return -1 ; }","title":"Memory Allocation"},{"location":"Mach/#memory-allocation-discussion","text":"In our code example, there are two stylistic points to note: We use a union to clearly characterise that Mach calls accept a handle, which is a vm_address_t but is clearly also just a raw pointer, char * , so we create a union comprising these two types depending on whether we are issuing Mach calls or doing normal C-based pointer arithmetic. The union avoids us having to use type casts. We use a goto idiom to handle errors. All our goto statements go forwards (so don't generate loops in our code) and just handle the error cases. This makes such exception handling clean without too much code repetition. That is useful because nearly all our function calls can return an error to be checked. In our code we make the following observations: We need to have the port of the task before any of the system calls can be made because any message port the system returns is namespaced to port of the task it relates to. mach_task_self() provides us this. It is not actually a function call, it is a #define which provides us our thread-specific task value. The value is typically a small integer. vm_allocate() allocates memory. It is logical to ask for a page sized amount of memory because this is the unit of memory upon which virtual protection and management is done. This will be 16 KiB. vm_read() actually also allocates memory as vm_allocate() does. The function names do not have a nomenclature that tells us this, so it is worthwhile checking the function meaning each time until we are familiar with them. vm_deallocate() deallocates our memory; we did a vm_allocate() and a vm_read() allocation so there are two pages of memory to free up. It is a good practice to check return values against != KERN_SUCCESS and let mach_error_string handle the different possible error return values, since there are many error values possible. This vm_example() code merely needs to be hooked into our App code when it launches, in the main() function to operate. It does feel heavyweight for what it does.","title":"Memory Allocation discussion"},{"location":"Mach/#copy-on-write-memory","text":"The following example shows how Mach will Copy-on-Write pages of memory which are shared. enum copy_on_write_constants { COPY_ON_WRITE = 0 , PARENT_CHANGED = 1 , CHILD_CHANGED = 2 , }; enum lock_constants { NO_ONE_WAIT = 0 , PARENT_WAIT = 1 , CHILD_WAIT = 2 }; char * lock_status [] = { \"NO_ONE_WAIT 0\" , \"PARENT_WAIT 1\" , \"CHILD_WAIT 2\" }; char * cow_status [] = { \"COPY_ON_WRITE 0\" , \"PARENT_CHANGED 1\" , \"CHILD_CHANGED 2\" }; int vm_copy_on_write_example () { union data_area { char * indexed ; vm_address_t handle ; } lock , mem ; mach_port_t self ; char * error = NULL ; kern_return_t rv = KERN_SUCCESS ; pid_t pid ; const int MAXDATA = 100 ; printf ( \" \\n START: vm_copy_on_write_example() \\n \" ); self = mach_task_self (); rv = vm_allocate ( self , & lock . handle , sizeof ( int ), TRUE ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_allocate\" ; goto vm_cow_error_return ; } rv = vm_inherit ( self , lock . handle , sizeof ( int ), VM_INHERIT_SHARE ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_inherit\" ; goto vm_cow_error_return ; } * lock . indexed = NO_ONE_WAIT ; rv = vm_allocate ( self , & mem . handle , sizeof ( int ) * MAXDATA , TRUE ); if ( rv != KERN_SUCCESS ) { error = \"Could not vm_allocate\" ; goto vm_cow_error_return ; } mem . indexed [ 0 ] = COPY_ON_WRITE ; printf ( \"value of lock before fork: %s \\n \" , lock_status [ * lock . indexed ]); pid = fork (); if ( pid ) { printf ( \"PARENT: copied memory = %s \\n \" , cow_status [ mem . indexed [ 0 ]]); printf ( \"PARENT: changing to %s \\n \" , cow_status [ PARENT_CHANGED ]); mem . indexed [ 0 ] = PARENT_CHANGED ; printf ( \" \\n \" ); printf ( \"PARENT: lock = %s \\n \" , lock_status [ * lock . indexed ]); printf ( \"PARENT: changing lock to %s \\n \" , lock_status [ PARENT_WAIT ]); printf ( \" \\n \" ); * lock . indexed = PARENT_WAIT ; while ( * lock . indexed == PARENT_WAIT ) { /* wait for child to change the value */ ; } printf ( \"PARENT: copied memory = %s \\n \" , cow_status [ mem . indexed [ 0 ]]); printf ( \"PARENT: lock = %s \\n \" , lock_status [ * lock . indexed ]); printf ( \"PARENT: Finished. \\n \" ); * lock . indexed = PARENT_WAIT ; exit ( -1 ); } while ( * lock . indexed != PARENT_WAIT ) { /* wait for parent to change lock */ ; } printf ( \"CHILD: copied memory = %s \\n \" , cow_status [ mem . indexed [ 0 ]]); printf ( \"CHILD: changing to %s \\n \" , cow_status [ CHILD_CHANGED ]); mem . indexed [ 0 ] = CHILD_CHANGED ; printf ( \" \\n \" ); printf ( \"CHILD: lock = %s \\n \" , lock_status [ * lock . indexed ]); printf ( \"CHILD: changing lock to %s \\n \" , lock_status [ CHILD_WAIT ]); printf ( \" \\n \" ); * lock . indexed = CHILD_WAIT ; while ( * lock . indexed == CHILD_WAIT ) { /* wait for parent to change lock */ ; } rv = vm_deallocate ( mach_task_self (), lock . handle , sizeof ( int )); if ( rv != KERN_SUCCESS ) { error = \"vm_deallocate failed\" ; goto vm_cow_error_return ; } rv = vm_deallocate ( mach_task_self (), mem . handle , sizeof ( int ) * MAXDATA ); if ( rv != KERN_SUCCESS ) { error = \"vm_deallocate failed\" ; goto vm_cow_error_return ; } printf ( \"CHILD: Finished. \\n \" ); printf ( \"END: vm_copy_on_write_example() \\n \" ); return 0 ; vm_cow_error_return : printf ( \"%s: %s \\n \" , error , mach_error_string ( rv )); return -1 ; } This program produces the following output: START: vm_copy_on_write_example() value of lock before fork: NO_ONE_WAIT 0 PARENT: copied memory = COPY_ON_WRITE 0 PARENT: changing to PARENT_CHANGED 1 PARENT: lock = NO_ONE_WAIT 0 PARENT: changing lock to PARENT_WAIT 1 CHILD: copied memory = COPY_ON_WRITE 0 CHILD: changing to CHILD_CHANGED 2 CHILD: lock = PARENT_WAIT 1 CHILD: changing lock to CHILD_WAIT 2 PARENT: copied memory = PARENT_CHANGED 1 PARENT: lock = CHILD_WAIT 2 PARENT: Finished. CHILD: Finished. END: vm_copy_on_write_example()","title":"Copy-on-Write Memory"},{"location":"Mach/#copy-on-write-discussion","text":"As we can see the vm_inherit() routine will provide both the child and parent access to the same memory until it is modified. After that, the child and parent have separate memory pages representing their own copy of the data values which can now be different. This program uses a very primitive form of task coordination: busy while loops. A realistic example would use the pthread library instead for signalling and coordination.","title":"Copy-on-Write Discussion"},{"location":"Mach/#further-steps","text":"We now leave the Mach programming introduction. There aren't really any big example programs that use Mach so it is hard to get an appreciation of how to program with it. The main Mach program is the XNU kernel itself. So our next steps on our learning journey is to understand how to debug and probe the XNU kernel. From this we can get live experience with how Mach works. We shall see how the system interacts with Mach and how security (Mandatory Access Control (MAC)) is woven into the system at this lowest level.","title":"Further steps"},{"location":"ZeroDay/","text":"Zero Day What is a Zero Day? A Zero Day Vulnerability is a security vulnerability which is not yet known to the vendor responsible for the platform that has the vulnerability. Once notified, the \"day\" value increases each day regardless of the action the vendor does. So a 300-Day vulnerability is one that has been reported to the vendor 300 days ago. It might have been patched on day 30. It might have been patched on day 90. It might never be patched. Even if it has been patched, a vulnerability disclosed 300 days ago is still a 300-Day vulnerability. As soon as a piece of software (it could also be firmware, a configuration file, resource file, etc.) is written the opportunity for a vulnerability arises. It could be that no one ever discovers the problem. Of the set of vulnerabilities that exist, some are found by humans (or their tools). At that point there is an asymmetry between those that know about the problem and those that do not know about the problem. Such knowledge can be valuable. That knowledge is sometimes traded, sold, or shared. Other times it is kept secret. It is only when the vendor is told about the vulnerability, that the bug is no longer a Zero Day Vulnerability. The date of disclosure then governs the \"day\" of the vulnerability. Bug Bounty Programmes In order to encourage disclosure of vulnerabilities, vendors sometimes have a bug bounty program. They can reward researchers with money, or a promise to contribute to a charity, or with fame by acknowledging them as finding the vulnerability. Since researchers sometimes hoard vulnerabilities so that can do further research unlocked by them, platform owners have responded by giving vetted researchers enhanced access. In particular, Apple has introduced the Security Research Device programme. Market Dynamics Sometimes multiple groups of engineers working separately find the same Zero Day. Sometimes a researcher suspects a bunch of related Zero Days, but only fully documents one. Likewise, sometimes the vendor only strictly fixes the vulnerability reported, and leaves adjacent issues as untreated. That in turn creates a dynamic in the market where recent bug fix releases are scanned for security fixes by researchers, so that adjacent issues can be explored. As the stock of vulnerabilities has increased over time, organisations have sought to organize and catalog such findings. This gives insights on the kinds of things that can go wrong. Vendors will improve their game by adding mitigations, which in turn will be researched for weaknesses. So it is a cat-and-mouse game, getting ever more sophisticated. If we consider \"The Road to Zero\" in dollar terms, where the dollar amount is the equipment cost, human time cost, etc. to achieve a 0-day, we can think of this book as a stepping stone. Firstly there is the cost to acquiring basic skills. Then there is the cost to acquiring similar skills but on iOS (Darwin) code bases. This book reduces that cost. Finally, there is the cost of finding original 0-days in iOS itself. We effectively make that final step cheaper because our skills have improved via the earlier steps. Market Evolution The market dynamics for iOS 0-day vulnerabilities has changed over time due to the changing nature of the Threat Model that Apple face, and the changing role iPhones and other devices have in our lives. Originally the iPhone had no third party apps. There were two main threats the system had to model. First were the Jailbreak community who wanted to customise the iPhone experience and add their own apps. Second were those that wanted to Carrier-unlock their phone. The phone price would typically be subsidized by the telecommunications operator via a subscription to their network over a period of time before we were allowed to buy a subscription to another operator. With such a threat model, a simple layer of defense was needed. Apple introduced the iPhone App Store, together with sandboxed apps, requiring code-signing for installation for all third party apps. In those days, a vulnerability alone was enough to defeat the security of the phone. So finding and exploiting a 0-day was \"most of the game\". Over the ensuing years, Apple would increase the depth of their defenses with new security measures, but bug hunters could keep up. However, the nature of the market changed. As there became more apps, and everyday work flows became connected to, and supported by, mobile phone apps, the value of the information in our phone drew the interest of government entities, criminals, and law-enforcement, as well as \"friends\" and family. Now the threat model is diverse and profound. The phone must resist attack when in physical possession of an attacker (such as a phone stolen after a crime). It must resist attack wirelessly when in a hostile network environment, such as an international conference hosting a politicaly sensitive agenda, or an innocent trip to a coffee shop. It must resist attack from a curious partner, grandparent or child. Since iDevices now have many layers of security, it is not one 0-day alone that unlock deeper access to the system. There are chains of vulnerabilities that need to be exploited to fully attack the system. Each subsystem has become a complex entity. So the market is now one of specialization. One person might be expert in WebKit vulnerabilities. One person might be expert in PDF file format weaknesses. One person might now how to construct \"gadgets\" to achieve a desired control flow path. There are companies that buy up individual vulnerabilities and assemble them. They might leverage toolkits from others for post-exploitation, etc. No one person is an industry. We are small players in a complex dynamic market. So it is important to understand what our goals are, what skills we have or desire, and how we see ourselves in this bigger picture. Monetary Rewards As the skill requirements have increased, together with increased specialization, the monetary cost of \"doing business\" has increased. This places security researchers in a novel \"taxation\" dynamic; see Why I Love and Don't Love Offensive Work . Apple will improve their security. Offensive security companies will need more money to crack into the iDevices as their exploit chains will become longer and more esoteric. They will need to buy in exploits, research material, and hire from a small pool of talent to do the equivalent in-house. Such companies will demand higher fees for their tools, and their solutions will have shorter lifetimes. Law enforcement, military and government entities will need to pay more for such tools. The pressure release value is at the political level. Either politicians agree to allowing strong protections in consumer devices, iPhone chiefly among them. This means taxation on the population (or a re-allocation of funds) to pay the offensive companies more money, and more often, for valuable access to mobile phone information. Or on the other hand, politicians can espouse back-doors into consumer devices. This lowers the \"taxation\" but increases malicious activity from adversaries. This explains our current surreal state of affairs. A vulnerabilty can be worth millions, because it is a tax on millions on users that require confidentiality, security and privacy. Ethics There are a lot of ethical consideration surrounding Zero Day Vulnerabilities (hereafter we shall say 0-day). The consensus is that we should not openly discuss or explain vulnerabilities until the bug is 90 days since disclosure (i.e. a 90-day). So we don't place 0-days in this text. But we create software modules of our own, reachable from a non-compromised device. These modules emulate closely the properties of an exposed subsystem so we can discuss, explore and compromise \"our own code\". We also discuss past vulnerabilities that have been patched by Apple. Will this book lead to a proliferation of 0-days? My opinion is that the malicious actors already have the tools and knowledge they need. It is the wider engineering community that need to up-skill in this area. Most of these people will not be malicious. They will enhance and improve the security of systems. In truth, we often tell ourselves stories that make us comfortable with what we are doing, particularly if our pay-cheque aligns with that. The best of intentions can result in adverse outcomes, as well as the converse. For example, a researcher working on their PhD might see a bug class, but just have time to explore one fully, writing up a Proof of Concept (POC), which is duly responsibly disclosed, and patched, before being published as a finding by the researcher. Another engineer might read the write-up, look at the binary diff related to the fix, notice associated vulnerabilities, and produce a variant POC and sell that to a market place for significant money. At that point, the vulnerability could be combined with others and militarized. The question is then who made that weapon, and would it have come to existence anyway? Such a weapon could be used to save lives, lose lives, start conflict or avoid conflict depending on the circumstances politically. Aren't security bugs just bugs? To take the opposite tack, we can ask ourselves, \"Aren't security bugs just bugs?\" In other words, why dwell on 0-days as something special. They are just bugs that can turn out to affect users when exploitable. But lots of things can affect users. To move forwards with the debate we need to be honest with ourselves. We need to understand our own perspective and agenda. If our goal is to learn how to find and discover 0-days, the process of discovery itself is the joy we seek. If that bug gets an associated vulnerability number, known as a CVE number, then it is a recognition of achievement, much the same as any other professional recognition. We do have to acknowledge the larger context. Platform owners know that in a large system, there will be bugs, and a subset of those will affect security. The vendor will know that part of their responsibility is patching the bugs when they have been reported. Their wider responsibility is to have processes that avoid the same issue appearing in the future, and avoid the same bug classes appearing. They may change their audit procedure, hire staff to search for bugs, provide training on secure programming practices, perform threat modelling sessions, etc. One fruitful area is applying mitigation layers. The platform may have checks against stack overflows, or malicious changes to control flow integrity, etc. These will be discussed later. In practice, these are powerful weapons. The ultimate perspective is that of an end-user. Users want to go about their business with the minimal amount of cost, and inconvenience, whilst having a rich and enjoyable user experience. A secure system which is so cumbersome that there are few users does little to help society. Users need psychological safety, and trust in their systems. A small drop of poison in a large reservoir wouldn't kill a person, but who would drink water from that reservoir? Security delivers safety and trust. So security bugs are important, but not special. They are important because over time platform vendors will develop mitigation layers to sweep away the exploitability of 0-days. And the platform vendors that do this in a way that minimises the cost and inconvenience to users will win over the greater number of users. This means that end users will live in a digital world that provides security and trust. And trust is essential to our modern day living. When we use public transit systems, we trust the safety of the transport system. When we stop by a coffee shop and order a drink, we assume the water in the drink is safe. Wealth is created by a division of labor with individuals doing specialist roles. Such a society can only function when those services are trustworthy. Computing services, such as mobile phone systems and apps are a key service that technologists contribute to the wider society. Going back to the example of public transit. When sitting on a train, we can often see a couple of people drinking coffee. But we can see plausibly a majority looking at their mobile phone screens. We need the train to be safe, the coffee to be safe, and the mobile computing experience to be safe! Burn Out We haven't even started yet, and so why are we bringing up the topic of burn out? When we start training our mind to think like a machine thinks, or start working through the details of a subsystem in great deal, it can be both engaging and exhausting. After a period of youthful exuberance we can fall into despair when we can nearly solve something, but cannot quite get it done. As ever, there is a way to hack around such problems! Looking after the body First, the boring stuff. Solid, regular and good-quality sleep. Three good meals a day. 30 minutes exercise a day - a good walk for example. These are the basics for maintaining our health. At least for now, humans are not machines, and humans need this basic level of care. Optimizing the mind Second, the mind hack. That first hour of the day, maybe the first half hour is the golden time. Save the heaviest and most difficult mental task to only that dream slot. Leave the manual, boring and tedious investigation work to the end of our work day. Everything else sits in-between those two things. Smoothing the ups and downs Third, the multi-tasking hack. If security research is the only thing we are doing, then yes we have focus but we are going to have ups and downs. The way around that is to have two activities that vary in importance over a period of months but are a constant presence. One good parallel activity is software engineering. We could be writing a security tool, for example, or something unrelated. Software engineering is in some ways the opposite of vulnerability research. It is building abstractions, adding layers, and working in a problem domain instead of the machine domain. It feels very constructive and creative. Sometimes we make great progress on our software, and other times we make progress on our vulnerability research. Since time away from one task does not stop our mind from advancing it in our the background, the net effect is that when we're done with vulnerability research, the software engineering seems to go great due to pent up ideas we've been working on in the background. The converse applies also, so that after a period of development on our software project, new ideas appear to help advance our security research. Using version control to contain complexity The fourth hack is facilitated by the git version control system. Everything we do must be recorded and tracked with git (or another version control system). Because with git, we can make small incremental improvements (git commits), and then build on those. This provides head space we need to achieve complex things. We just keep incrementally developing our ideas, code, and experiments. Do not try and keep complexity in our mind for a long period. Just keep dumping them into text files, code, etc., into a git repository. Then at the end of each day, we will feel that we made progress, even if there is no big result. That will save our sanity. Resources To complement the book, there is a website of resources which is intended to be used alongside the printed material so example projects can be setup and experimented with. All references in this book are collected into the Bibliography Chapter at the end of the book. There we will find URLs to resources, for example. The GitHub website supporting the book is at The Road to Zero on GitHub","title":"Zero Day"},{"location":"ZeroDay/#zero-day","text":"","title":"Zero Day"},{"location":"ZeroDay/#what-is-a-zero-day","text":"A Zero Day Vulnerability is a security vulnerability which is not yet known to the vendor responsible for the platform that has the vulnerability. Once notified, the \"day\" value increases each day regardless of the action the vendor does. So a 300-Day vulnerability is one that has been reported to the vendor 300 days ago. It might have been patched on day 30. It might have been patched on day 90. It might never be patched. Even if it has been patched, a vulnerability disclosed 300 days ago is still a 300-Day vulnerability. As soon as a piece of software (it could also be firmware, a configuration file, resource file, etc.) is written the opportunity for a vulnerability arises. It could be that no one ever discovers the problem. Of the set of vulnerabilities that exist, some are found by humans (or their tools). At that point there is an asymmetry between those that know about the problem and those that do not know about the problem. Such knowledge can be valuable. That knowledge is sometimes traded, sold, or shared. Other times it is kept secret. It is only when the vendor is told about the vulnerability, that the bug is no longer a Zero Day Vulnerability. The date of disclosure then governs the \"day\" of the vulnerability.","title":"What is a Zero Day?"},{"location":"ZeroDay/#bug-bounty-programmes","text":"In order to encourage disclosure of vulnerabilities, vendors sometimes have a bug bounty program. They can reward researchers with money, or a promise to contribute to a charity, or with fame by acknowledging them as finding the vulnerability. Since researchers sometimes hoard vulnerabilities so that can do further research unlocked by them, platform owners have responded by giving vetted researchers enhanced access. In particular, Apple has introduced the Security Research Device programme.","title":"Bug Bounty Programmes"},{"location":"ZeroDay/#market-dynamics","text":"Sometimes multiple groups of engineers working separately find the same Zero Day. Sometimes a researcher suspects a bunch of related Zero Days, but only fully documents one. Likewise, sometimes the vendor only strictly fixes the vulnerability reported, and leaves adjacent issues as untreated. That in turn creates a dynamic in the market where recent bug fix releases are scanned for security fixes by researchers, so that adjacent issues can be explored. As the stock of vulnerabilities has increased over time, organisations have sought to organize and catalog such findings. This gives insights on the kinds of things that can go wrong. Vendors will improve their game by adding mitigations, which in turn will be researched for weaknesses. So it is a cat-and-mouse game, getting ever more sophisticated. If we consider \"The Road to Zero\" in dollar terms, where the dollar amount is the equipment cost, human time cost, etc. to achieve a 0-day, we can think of this book as a stepping stone. Firstly there is the cost to acquiring basic skills. Then there is the cost to acquiring similar skills but on iOS (Darwin) code bases. This book reduces that cost. Finally, there is the cost of finding original 0-days in iOS itself. We effectively make that final step cheaper because our skills have improved via the earlier steps.","title":"Market Dynamics"},{"location":"ZeroDay/#market-evolution","text":"The market dynamics for iOS 0-day vulnerabilities has changed over time due to the changing nature of the Threat Model that Apple face, and the changing role iPhones and other devices have in our lives. Originally the iPhone had no third party apps. There were two main threats the system had to model. First were the Jailbreak community who wanted to customise the iPhone experience and add their own apps. Second were those that wanted to Carrier-unlock their phone. The phone price would typically be subsidized by the telecommunications operator via a subscription to their network over a period of time before we were allowed to buy a subscription to another operator. With such a threat model, a simple layer of defense was needed. Apple introduced the iPhone App Store, together with sandboxed apps, requiring code-signing for installation for all third party apps. In those days, a vulnerability alone was enough to defeat the security of the phone. So finding and exploiting a 0-day was \"most of the game\". Over the ensuing years, Apple would increase the depth of their defenses with new security measures, but bug hunters could keep up. However, the nature of the market changed. As there became more apps, and everyday work flows became connected to, and supported by, mobile phone apps, the value of the information in our phone drew the interest of government entities, criminals, and law-enforcement, as well as \"friends\" and family. Now the threat model is diverse and profound. The phone must resist attack when in physical possession of an attacker (such as a phone stolen after a crime). It must resist attack wirelessly when in a hostile network environment, such as an international conference hosting a politicaly sensitive agenda, or an innocent trip to a coffee shop. It must resist attack from a curious partner, grandparent or child. Since iDevices now have many layers of security, it is not one 0-day alone that unlock deeper access to the system. There are chains of vulnerabilities that need to be exploited to fully attack the system. Each subsystem has become a complex entity. So the market is now one of specialization. One person might be expert in WebKit vulnerabilities. One person might be expert in PDF file format weaknesses. One person might now how to construct \"gadgets\" to achieve a desired control flow path. There are companies that buy up individual vulnerabilities and assemble them. They might leverage toolkits from others for post-exploitation, etc. No one person is an industry. We are small players in a complex dynamic market. So it is important to understand what our goals are, what skills we have or desire, and how we see ourselves in this bigger picture.","title":"Market Evolution"},{"location":"ZeroDay/#monetary-rewards","text":"As the skill requirements have increased, together with increased specialization, the monetary cost of \"doing business\" has increased. This places security researchers in a novel \"taxation\" dynamic; see Why I Love and Don't Love Offensive Work . Apple will improve their security. Offensive security companies will need more money to crack into the iDevices as their exploit chains will become longer and more esoteric. They will need to buy in exploits, research material, and hire from a small pool of talent to do the equivalent in-house. Such companies will demand higher fees for their tools, and their solutions will have shorter lifetimes. Law enforcement, military and government entities will need to pay more for such tools. The pressure release value is at the political level. Either politicians agree to allowing strong protections in consumer devices, iPhone chiefly among them. This means taxation on the population (or a re-allocation of funds) to pay the offensive companies more money, and more often, for valuable access to mobile phone information. Or on the other hand, politicians can espouse back-doors into consumer devices. This lowers the \"taxation\" but increases malicious activity from adversaries. This explains our current surreal state of affairs. A vulnerabilty can be worth millions, because it is a tax on millions on users that require confidentiality, security and privacy.","title":"Monetary Rewards"},{"location":"ZeroDay/#ethics","text":"There are a lot of ethical consideration surrounding Zero Day Vulnerabilities (hereafter we shall say 0-day). The consensus is that we should not openly discuss or explain vulnerabilities until the bug is 90 days since disclosure (i.e. a 90-day). So we don't place 0-days in this text. But we create software modules of our own, reachable from a non-compromised device. These modules emulate closely the properties of an exposed subsystem so we can discuss, explore and compromise \"our own code\". We also discuss past vulnerabilities that have been patched by Apple. Will this book lead to a proliferation of 0-days? My opinion is that the malicious actors already have the tools and knowledge they need. It is the wider engineering community that need to up-skill in this area. Most of these people will not be malicious. They will enhance and improve the security of systems. In truth, we often tell ourselves stories that make us comfortable with what we are doing, particularly if our pay-cheque aligns with that. The best of intentions can result in adverse outcomes, as well as the converse. For example, a researcher working on their PhD might see a bug class, but just have time to explore one fully, writing up a Proof of Concept (POC), which is duly responsibly disclosed, and patched, before being published as a finding by the researcher. Another engineer might read the write-up, look at the binary diff related to the fix, notice associated vulnerabilities, and produce a variant POC and sell that to a market place for significant money. At that point, the vulnerability could be combined with others and militarized. The question is then who made that weapon, and would it have come to existence anyway? Such a weapon could be used to save lives, lose lives, start conflict or avoid conflict depending on the circumstances politically.","title":"Ethics"},{"location":"ZeroDay/#arent-security-bugs-just-bugs","text":"To take the opposite tack, we can ask ourselves, \"Aren't security bugs just bugs?\" In other words, why dwell on 0-days as something special. They are just bugs that can turn out to affect users when exploitable. But lots of things can affect users. To move forwards with the debate we need to be honest with ourselves. We need to understand our own perspective and agenda. If our goal is to learn how to find and discover 0-days, the process of discovery itself is the joy we seek. If that bug gets an associated vulnerability number, known as a CVE number, then it is a recognition of achievement, much the same as any other professional recognition. We do have to acknowledge the larger context. Platform owners know that in a large system, there will be bugs, and a subset of those will affect security. The vendor will know that part of their responsibility is patching the bugs when they have been reported. Their wider responsibility is to have processes that avoid the same issue appearing in the future, and avoid the same bug classes appearing. They may change their audit procedure, hire staff to search for bugs, provide training on secure programming practices, perform threat modelling sessions, etc. One fruitful area is applying mitigation layers. The platform may have checks against stack overflows, or malicious changes to control flow integrity, etc. These will be discussed later. In practice, these are powerful weapons. The ultimate perspective is that of an end-user. Users want to go about their business with the minimal amount of cost, and inconvenience, whilst having a rich and enjoyable user experience. A secure system which is so cumbersome that there are few users does little to help society. Users need psychological safety, and trust in their systems. A small drop of poison in a large reservoir wouldn't kill a person, but who would drink water from that reservoir? Security delivers safety and trust. So security bugs are important, but not special. They are important because over time platform vendors will develop mitigation layers to sweep away the exploitability of 0-days. And the platform vendors that do this in a way that minimises the cost and inconvenience to users will win over the greater number of users. This means that end users will live in a digital world that provides security and trust. And trust is essential to our modern day living. When we use public transit systems, we trust the safety of the transport system. When we stop by a coffee shop and order a drink, we assume the water in the drink is safe. Wealth is created by a division of labor with individuals doing specialist roles. Such a society can only function when those services are trustworthy. Computing services, such as mobile phone systems and apps are a key service that technologists contribute to the wider society. Going back to the example of public transit. When sitting on a train, we can often see a couple of people drinking coffee. But we can see plausibly a majority looking at their mobile phone screens. We need the train to be safe, the coffee to be safe, and the mobile computing experience to be safe!","title":"Aren't security bugs just bugs?"},{"location":"ZeroDay/#burn-out","text":"We haven't even started yet, and so why are we bringing up the topic of burn out? When we start training our mind to think like a machine thinks, or start working through the details of a subsystem in great deal, it can be both engaging and exhausting. After a period of youthful exuberance we can fall into despair when we can nearly solve something, but cannot quite get it done. As ever, there is a way to hack around such problems!","title":"Burn Out"},{"location":"ZeroDay/#looking-after-the-body","text":"First, the boring stuff. Solid, regular and good-quality sleep. Three good meals a day. 30 minutes exercise a day - a good walk for example. These are the basics for maintaining our health. At least for now, humans are not machines, and humans need this basic level of care.","title":"Looking after the body"},{"location":"ZeroDay/#optimizing-the-mind","text":"Second, the mind hack. That first hour of the day, maybe the first half hour is the golden time. Save the heaviest and most difficult mental task to only that dream slot. Leave the manual, boring and tedious investigation work to the end of our work day. Everything else sits in-between those two things.","title":"Optimizing the mind"},{"location":"ZeroDay/#smoothing-the-ups-and-downs","text":"Third, the multi-tasking hack. If security research is the only thing we are doing, then yes we have focus but we are going to have ups and downs. The way around that is to have two activities that vary in importance over a period of months but are a constant presence. One good parallel activity is software engineering. We could be writing a security tool, for example, or something unrelated. Software engineering is in some ways the opposite of vulnerability research. It is building abstractions, adding layers, and working in a problem domain instead of the machine domain. It feels very constructive and creative. Sometimes we make great progress on our software, and other times we make progress on our vulnerability research. Since time away from one task does not stop our mind from advancing it in our the background, the net effect is that when we're done with vulnerability research, the software engineering seems to go great due to pent up ideas we've been working on in the background. The converse applies also, so that after a period of development on our software project, new ideas appear to help advance our security research.","title":"Smoothing the ups and downs"},{"location":"ZeroDay/#using-version-control-to-contain-complexity","text":"The fourth hack is facilitated by the git version control system. Everything we do must be recorded and tracked with git (or another version control system). Because with git, we can make small incremental improvements (git commits), and then build on those. This provides head space we need to achieve complex things. We just keep incrementally developing our ideas, code, and experiments. Do not try and keep complexity in our mind for a long period. Just keep dumping them into text files, code, etc., into a git repository. Then at the end of each day, we will feel that we made progress, even if there is no big result. That will save our sanity.","title":"Using version control to contain complexity"},{"location":"ZeroDay/#resources","text":"To complement the book, there is a website of resources which is intended to be used alongside the printed material so example projects can be setup and experimented with. All references in this book are collected into the Bibliography Chapter at the end of the book. There we will find URLs to resources, for example. The GitHub website supporting the book is at The Road to Zero on GitHub","title":"Resources"}]}